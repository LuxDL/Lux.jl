function batchnorm_cudnn end   # Defined in LuxLibcuDNNExt
function âˆ‡batchnorm_cudnn end  # Defined in LuxLibcuDNNExt

function batchnorm_reduce_dims(::AbstractArray{T, N}) where {T, N}
    return (ntuple(static, N - 2)..., static(N))
end

CRC.@non_differentiable batchnorm_reduce_dims(::Any...)

function get_batchnorm_statistics(::AbstractArray, rÎ¼::Optional{<:AbstractVector},
        rÏƒÂ²::Optional{<:AbstractVector}, ::True)
    return Utils.copy_drop_gradients(rÎ¼), Utils.copy_drop_gradients(rÏƒÂ²)
end

function get_batchnorm_statistics(x::AbstractArray, ::Nothing, ::Nothing, ::False)
    Î¼, ÏƒÂ² = mean_var(x; dims=Utils.known(batchnorm_reduce_dims(x)), corrected=false)
    return Utils.vec(Î¼), Utils.vec(ÏƒÂ²)
end

function get_batchnorm_statistics(
        ::AbstractArray, rÎ¼::AbstractVector, rÏƒÂ²::AbstractVector, ::False)
    return rÎ¼, rÏƒÂ²
end

CRC.@non_differentiable get_batchnorm_statistics(::Any...)

function batchnorm(x::AbstractArray{<:Number, N}, Î³::Optional{<:AbstractVector},
        Î²::Optional{<:AbstractVector}, rÎ¼::Optional{<:AbstractVector},
        rÏƒÂ²::Optional{<:AbstractVector}, training::StaticBool,
        act::F, momentum::Real, Ïµ::Real) where {F, N}
    (Î¼, ÏƒÂ²), (rÎ¼, rÏƒÂ²) = compute_batch_statistics(
        x, reshape_norm_dims(x, rÎ¼), reshape_norm_dims(x, rÏƒÂ²),
        batchnorm_reduce_dims(x), training, momentum)
    return (batchnorm_affine_normalize(act, x, Î¼, ÏƒÂ², Î³, Î², Ïµ),
        get_utils(:vec)(rÎ¼), get_utils(:vec)(rÏƒÂ²))
end

function batchnorm_affine_normalize(
        act::F, x::AbstractArray{<:Number, N}, Î¼::AbstractArray{<:Number, N},
        ÏƒÂ²::AbstractArray{<:Number, N}, Î³::Optional{<:AbstractVector},
        Î²::Optional{<:AbstractVector}, Ïµ::Real) where {N, F}
    return batchnorm_affine_normalize(
        internal_operation_mode((x, Î¼, ÏƒÂ², Î³, Î²)), act, x, Î¼, ÏƒÂ², Î³, Î², Ïµ)
end

function batchnorm_affine_normalize(
        ::GenericBroadcastOp, act::F, x::AbstractArray{<:Number, N},
        Î¼::AbstractArray{<:Number, N}, ÏƒÂ²::AbstractArray{<:Number, N},
        Î³::Optional{<:AbstractVector}, Î²::Optional{<:AbstractVector}, Ïµ::Real) where {F, N}
    return affine_normalize(
        act, x, Î¼, ÏƒÂ², reshape_norm_dims(x, Î³), reshape_norm_dims(x, Î²), Ïµ)
end

function batchnorm_affine_normalize(
        opmode::AbstractInternalArrayOpMode, act::F, x::AbstractArray{<:Number, N},
        Î¼::AbstractArray{<:Number, N}, ÏƒÂ²::AbstractArray{<:Number, N},
        Î³::Optional{<:AbstractVector}, Î²::Optional{<:AbstractVector}, Ïµ::Real) where {F, N}
    xâ€² = reshape(x, :, size(x, N - 1), size(x, N))
    return reshape(
        batchnorm_affine_normalize_internal(opmode, act, xâ€², vec(Î¼), vec(ÏƒÂ²), Î³, Î², Ïµ),
        size(x))
end

@stable default_mode="disable" function batchnorm_affine_normalize_internal(
        opmode::AbstractInternalArrayOpMode, act::F, x::AbstractArray{<:Number, 3},
        Î¼::AbstractVector, ÏƒÂ²::AbstractVector, Î³::Optional{<:AbstractVector},
        Î²::Optional{<:AbstractVector}, Ïµ::Real) where {F}
    y = similar(x,
        promote_type(Utils.eltype(x), Utils.eltype(Î¼), Utils.eltype(ÏƒÂ²),
            Utils.eltype(Î³), Utils.eltype(Î²)))
    batchnorm_affine_normalize_internal!(y, opmode, act, x, Î¼, ÏƒÂ², Î³, Î², Ïµ)
    return y
end

function batchnorm_affine_normalize_internal!(
        y::AbstractArray{<:Number, 3}, opmode::LoopedArrayOp, act::F,
        x::AbstractArray{<:Number, 3}, Î¼::AbstractVector, ÏƒÂ²::AbstractVector,
        Î³::Optional{<:AbstractVector}, Î²::Optional{<:AbstractVector},
        Ïµ::Real, Î³â€²::Optional{<:AbstractVector}=nothing) where {F}
    N = size(y, 2)
    Î³â€² = Î³â€² === nothing ?
         similar(x, promote_type(Utils.eltype(Î³), Utils.eltype(ÏƒÂ²), Utils.eltype(Ïµ)), N) :
         Î³â€²
    Î²â€² = similar(x, promote_type(Utils.eltype(Î²), Utils.eltype(ÏƒÂ²), Utils.eltype(Ïµ)), N)

    compute_batchnorm_scale_bias_loopvec!(Î³â€², Î²â€², Î³, Î², Î¼, ÏƒÂ², Ïµ)
    apply_batchnorm_scale_bias!(y, Î³â€², Î²â€², x)
    activation!(y, opmode, act, y)
    return
end

function compute_batchnorm_scale_bias_loopvec!(Î³â€², Î²â€², ::Nothing, ::Nothing, Î¼, ÏƒÂ², Ïµ)
    if LV.check_args(Î³â€², Î²â€², Î¼, ÏƒÂ²)
        @tturbo for J in indices((Î³â€², Î²â€², Î¼, ÏƒÂ²))
            Î³â€²[J] = inv(sqrt(ÏƒÂ²[J] + Ïµ))
            Î²â€²[J] = -Î¼[J] * Î³â€²[J]
        end
    else
        @batch for J in indices((Î³â€², Î²â€², Î¼, ÏƒÂ²))
            @inbounds Î³â€²[J] = inv(sqrt(ÏƒÂ²[J] + Ïµ))
            @inbounds Î²â€²[J] = -Î¼[J] * Î³â€²[J]
        end
    end
end

function compute_batchnorm_scale_bias_loopvec!(Î³â€², Î²â€², Î³, Î², Î¼, ÏƒÂ², Ïµ)
    if LV.check_args(Î³â€², Î²â€², Î³, Î², Î¼, ÏƒÂ²)
        @tturbo for J in indices((Î³â€², Î²â€², Î³, Î², Î¼, ÏƒÂ²))
            Î³â€²[J] = Î³[J] / sqrt(ÏƒÂ²[J] + Ïµ)
            Î²â€²[J] = Î²[J] - Î¼[J] * Î³â€²[J]
        end
    else
        @batch for J in indices((Î³â€², Î²â€², Î³, Î², Î¼, ÏƒÂ²))
            @inbounds Î³â€²[J] = Î³[J] / sqrt(ÏƒÂ²[J] + Ïµ)
            @inbounds Î²â€²[J] = Î²[J] - Î¼[J] * Î³â€²[J]
        end
    end
end

function compute_batchnorm_scale_bias_simd_loop!(Î³â€², Î²â€², ::Nothing, ::Nothing, Î¼, ÏƒÂ², Ïµ)
    @simd ivdep for J in indices((Î³â€², Î²â€², Î¼, ÏƒÂ²))
        @inbounds Î³â€²[J] = inv(sqrt(ÏƒÂ²[J] + Ïµ))
        @inbounds Î²â€²[J] = -Î¼[J] * Î³â€²[J]
    end
end

function compute_batchnorm_scale_bias_simd_loop!(Î³â€², Î²â€², Î³, Î², Î¼, ÏƒÂ², Ïµ)
    @simd ivdep for J in indices((Î³â€², Î²â€², Î³, Î², Î¼, ÏƒÂ²))
        @inbounds Î³â€²[J] = Î³[J] / sqrt(ÏƒÂ²[J] + Ïµ)
        @inbounds Î²â€²[J] = Î²[J] - Î¼[J] * Î³â€²[J]
    end
end

Utils.@enzyme_reverse_alternative compute_batchnorm_scale_bias_loopvec! compute_batchnorm_scale_bias_simd_loop!

function apply_batchnorm_scale_bias!(y::AbstractArray{<:Number, 3}, Î³â€²::AbstractVector,
        Î²â€²::AbstractVector, x::AbstractArray{<:Number, 3})
    if LV.check_args(y, Î³â€², Î²â€², x)
        @tturbo for K in indices((x, y), 3),
            J in indices((x, y, Î³â€², Î²â€²), (2, 2, 1, 1)),
            I in indices((x, y), 1)

            y[I, J, K] = x[I, J, K] * Î³â€²[J] + Î²â€²[J]
        end
    else
        @batch for K in indices((x, y), 3), J in indices((x, y, Î³â€², Î²â€²), (2, 2, 1, 1))
            @simd ivdep for I in indices((x, y), 1)
                @inbounds y[I, J, K] = x[I, J, K] * Î³â€²[J] + Î²â€²[J]
            end
        end
    end
end

function apply_batchnorm_scale_bias_simd_loop!(
        y::AbstractArray{<:Number, 3}, Î³â€²::AbstractVector,
        Î²â€²::AbstractVector, x::AbstractArray{<:Number, 3})
    for K in indices((x, y), 3), J in indices((x, y, Î³â€², Î²â€²), (2, 2, 1, 1))
        @simd ivdep for I in indices((x, y), 1)
            @inbounds y[I, J, K] = x[I, J, K] * Î³â€²[J] + Î²â€²[J]
        end
    end
end

Utils.@enzyme_reverse_alternative apply_batchnorm_scale_bias! apply_batchnorm_scale_bias_simd_loop!

function batchnorm_affine_normalize_internal!(
        y::AbstractArray{<:Number, 3}, ::GPUBroadcastOp, act::F,
        x::AbstractArray{<:Number, 3}, Î¼::AbstractVector, ÏƒÂ²::AbstractVector,
        Î³::Optional{<:AbstractVector}, Î²::Optional{<:AbstractVector},
        Ïµ::Real, Î³â€²::Optional{<:AbstractVector}=nothing) where {F}
    backend = KA.get_backend(y)
    if Î³â€² === nothing
        kernel! = batchnorm_affine_normalize_internal_kernel!(backend)
        kernel!(y, act, x, Î¼, ÏƒÂ², Î³, Î², Ïµ; ndrange=size(y))
    else
        kernel! = batchnorm_affine_normalize_internal_kernel_cached!(backend)
        kernel!(y, Î³â€², act, x, Î¼, ÏƒÂ², Î³, Î², Ïµ; ndrange=size(y))
    end
    KA.synchronize(backend)
end

@kernel function batchnorm_affine_normalize_internal_kernel!(
        y::AbstractArray{<:Number, 3}, @Const(f), @Const(x),
        @Const(Î¼), @Const(ÏƒÂ²), @Const(Î³), @Const(Î²), @Const(Ïµ))
    (i, j, k) = @index(Global, NTuple)
    if Î³ !== nothing
        @inbounds Î³â€² = Î³[j] / sqrt(ÏƒÂ²[j] + Ïµ)
        @inbounds Î²â€² = muladd(-Î¼[j], Î³â€², Î²[j])
    else
        @inbounds Î³â€² = inv(sqrt(ÏƒÂ²[j] + Ïµ))
        @inbounds Î²â€² = -Î¼[j] * Î³â€²
    end
    @inbounds y[i, j, k] = f(muladd(x[i, j, k], Î³â€², Î²â€²))
end

@kernel function batchnorm_affine_normalize_internal_kernel_cached!(
        y::AbstractArray{<:Number, 3}, Î³â€²::AbstractVector{<:Number}, @Const(f),
        @Const(x), @Const(Î¼), @Const(ÏƒÂ²), @Const(Î³), @Const(Î²), @Const(Ïµ))
    (i, j, k) = @index(Global, NTuple)
    if Î³ !== nothing
        @inbounds Î³â€²[j] = Î³[j] / sqrt(ÏƒÂ²[j] + Ïµ)
        @inbounds Î²â€² = muladd(-Î¼[j], Î³â€²[j], Î²[j])
    else
        @inbounds Î³â€²[j] = inv(sqrt(ÏƒÂ²[j] + Ïµ))
        @inbounds Î²â€² = -Î¼[j] * Î³â€²[j]
    end
    @inbounds y[i, j, k] = f(muladd(x[i, j, k], Î³â€²[j], Î²â€²))
end

function CRC.rrule(
        cfg::RuleConfig{>:HasReverseMode}, ::typeof(batchnorm_affine_normalize_internal),
        opmode::AbstractInternalArrayOpMode, act::F, x::AbstractArray{T, N},
        Î¼::AbstractVector, ÏƒÂ²::AbstractVector, Î³::Optional{<:AbstractVector},
        Î²::Optional{<:AbstractVector}, Ïµ::Real) where {F, T, N}
    y = similar(x,
        promote_type(Utils.eltype(x), Utils.eltype(Î¼), Utils.eltype(ÏƒÂ²),
            Utils.eltype(Î³), Utils.eltype(Î²)))
    Î³â€² = similar(
        x, promote_type(Utils.eltype(Î³), Utils.eltype(ÏƒÂ²), Utils.eltype(Ïµ)), size(x, N - 1))

    batchnorm_affine_normalize_internal!(y, opmode, identity, x, Î¼, ÏƒÂ², Î³, Î², Ïµ, Î³â€²)
    z, âˆ‡activation = CRC.rrule_via_ad(
        cfg, activation!!, opmode, Traits.is_mutable_array(y), act, y)

    ğ’«x, ğ’«Î¼, ğ’«ÏƒÂ² = CRC.ProjectTo(x), CRC.ProjectTo(Î¼), CRC.ProjectTo(ÏƒÂ²)
    ğ’«Î³ = Î³ === nothing ? identity : CRC.ProjectTo(Î³)
    ğ’«Î² = Î² === nothing ? identity : CRC.ProjectTo(Î²)

    âˆ‡batchnorm_affine_normalize_internal = @closure Î” -> begin
        âˆ‚y = last(âˆ‡activation(Î”))
        âˆ‚x, âˆ‚Î¼, âˆ‚ÏƒÂ², âˆ‚Î³, âˆ‚Î² = âˆ‡batchnorm_affine_normalize(opmode, âˆ‚y, x, Î¼, ÏƒÂ², Î³, Î², Ïµ, Î³â€²)
        return âˆ‚âˆ…, âˆ‚âˆ…, âˆ‚âˆ…, ğ’«x(âˆ‚x), ğ’«Î¼(âˆ‚Î¼), ğ’«ÏƒÂ²(âˆ‚ÏƒÂ²), ğ’«Î³(âˆ‚Î³), ğ’«Î²(âˆ‚Î²), âˆ‚âˆ…
    end

    return z, âˆ‡batchnorm_affine_normalize_internal
end

function âˆ‡batchnorm_affine_normalize(
        opmode::AbstractInternalArrayOpMode, âˆ‚y::AbstractArray{<:Number, 3},
        x::AbstractArray{<:Number, 3}, Î¼::AbstractVector,
        ÏƒÂ²::AbstractVector, Î³::Optional{<:AbstractVector},
        Î²::Optional{<:AbstractVector}, Ïµ::Real, Î³â€²::AbstractVector)
    âˆ‚x, âˆ‚ÏƒÂ² = similar(x), similar(ÏƒÂ², size(x))
    âˆ‚Î³ = Î³ === nothing ? nothing : similar(Î³, size(x))

    âˆ‡batchnorm_affine_normalize!(âˆ‚x, âˆ‚ÏƒÂ², âˆ‚Î³, opmode, âˆ‚y, x, Î¼, ÏƒÂ², Î³, Ïµ, Î³â€²)

    âˆ‚Î¼ = dropdims(sum(-, âˆ‚x; dims=(1, 3)); dims=(1, 3))
    âˆ‚ÏƒÂ² = dropdims(sum(âˆ‚ÏƒÂ²; dims=(1, 3)); dims=(1, 3))
    âˆ‚Î³ = Î³ === nothing ? âˆ‚âˆ… : dropdims(sum(âˆ‚Î³; dims=(1, 3)); dims=(1, 3))
    âˆ‚Î² = Î² === nothing ? âˆ‚âˆ… : dropdims(sum(âˆ‚y; dims=(1, 3)); dims=(1, 3))

    return âˆ‚x, âˆ‚Î¼, âˆ‚ÏƒÂ², âˆ‚Î³, âˆ‚Î²
end

function âˆ‡batchnorm_affine_normalize!(
        âˆ‚x::AbstractArray{<:Number, 3}, âˆ‚ÏƒÂ²::AbstractArray{<:Number, 3}, ::Nothing,
        ::LoopedArrayOp, âˆ‚y::AbstractArray{<:Number, 3}, x::AbstractArray{<:Number, 3},
        Î¼::AbstractVector, ÏƒÂ²::AbstractVector, ::Nothing, Ïµ::Real, Î³â€²::AbstractVector)
    half = eltype(âˆ‚ÏƒÂ²)(0.5)

    if LV.check_args(âˆ‚x, âˆ‚ÏƒÂ², âˆ‚y, x, Î¼, ÏƒÂ²)
        @tturbo for K in indices(âˆ‚y, 3), J in indices(âˆ‚y, 2)
            idenom = Î³â€²[J]
            idenomÂ² = idenom^2

            for I in indices(âˆ‚y, 1)
                xÎ¼ = x[I, J, K] - Î¼[J]

                âˆ‚x[I, J, K] = âˆ‚y[I, J, K] * idenom
                âˆ‚ÏƒÂ²[I, J, K] = -âˆ‚x[I, J, K] * xÎ¼ * half * idenomÂ²
            end
        end
    else
        @inbounds @batch for K in indices(âˆ‚y, 3), J in indices(âˆ‚y, 2)
            idenom = Î³â€²[J]
            idenomÂ² = idenom^2

            @simd for I in indices(âˆ‚y, 1)
                xÎ¼ = x[I, J, K] - Î¼[J]

                âˆ‚x[I, J, K] = âˆ‚y[I, J, K] * idenom
                âˆ‚ÏƒÂ²[I, J, K] = -âˆ‚x[I, J, K] * xÎ¼ * half * idenomÂ²
            end
        end
    end
end

function âˆ‡batchnorm_affine_normalize!(
        âˆ‚x::AbstractArray{<:Number, 3}, âˆ‚ÏƒÂ²::AbstractArray{<:Number, 3},
        âˆ‚Î³::AbstractArray{<:Number, 3}, ::LoopedArrayOp, âˆ‚y::AbstractArray{<:Number, 3},
        x::AbstractArray{<:Number, 3}, Î¼::AbstractVector,
        ÏƒÂ²::AbstractVector, Î³::AbstractVector, Ïµ::Real, Î³â€²::AbstractVector)
    half = eltype(âˆ‚ÏƒÂ²)(0.5)

    if LV.check_args(âˆ‚x, âˆ‚ÏƒÂ², âˆ‚Î³, âˆ‚y, x, Î¼, ÏƒÂ², Î³)
        @tturbo for K in indices(âˆ‚y, 3), J in indices(âˆ‚y, 2)
            idenom = inv(sqrt(ÏƒÂ²[J] + Ïµ))
            idenomÂ² = idenom^2

            for I in indices(âˆ‚y, 1)
                xÎ¼ = x[I, J, K] - Î¼[J]

                âˆ‚x[I, J, K] = âˆ‚y[I, J, K] * Î³â€²[J]
                âˆ‚ÏƒÂ²[I, J, K] = -âˆ‚x[I, J, K] * xÎ¼ * half * idenomÂ²
                âˆ‚Î³[I, J, K] = âˆ‚y[I, J, K] * xÎ¼ * idenom
            end
        end
    else
        @inbounds @batch for K in indices(âˆ‚y, 3), J in indices(âˆ‚y, 2)
            idenom = inv(sqrt(ÏƒÂ²[J] + Ïµ))
            idenomÂ² = idenom^2

            @simd for I in indices(âˆ‚y, 1)
                xÎ¼ = x[I, J, K] - Î¼[J]

                âˆ‚x[I, J, K] = âˆ‚y[I, J, K] * Î³â€²[J]
                âˆ‚ÏƒÂ²[I, J, K] = -âˆ‚x[I, J, K] * xÎ¼ * half * idenomÂ²
                âˆ‚Î³[I, J, K] = âˆ‚y[I, J, K] * xÎ¼ * idenom
            end
        end
    end
end

function âˆ‡batchnorm_affine_normalize!(
        âˆ‚x::AbstractArray{<:Number, 3}, âˆ‚ÏƒÂ²::AbstractArray{<:Number, 3},
        âˆ‚Î³::Optional{<:AbstractArray{<:Number, 3}}, ::GPUBroadcastOp,
        âˆ‚y::AbstractArray{<:Number, 3}, x::AbstractArray{<:Number, 3}, Î¼::AbstractVector,
        ÏƒÂ²::AbstractVector, Î³::Optional{<:AbstractVector}, Ïµ::Real, Î³â€²::AbstractVector)
    backend = KA.get_backend(âˆ‚x)
    kernel! = âˆ‡batchnorm_affine_normalize_kernel!(backend)
    kernel!(âˆ‚x, âˆ‚ÏƒÂ², âˆ‚Î³, âˆ‚y, x, Î¼, ÏƒÂ², Î³, Ïµ, Î³â€²; ndrange=size(âˆ‚x))
    KA.synchronize(backend)
end

@kernel function âˆ‡batchnorm_affine_normalize_kernel!(
        âˆ‚x, âˆ‚ÏƒÂ², âˆ‚Î³, @Const(âˆ‚y), @Const(x), @Const(Î¼),
        @Const(ÏƒÂ²), @Const(Î³), @Const(Ïµ), @Const(Î³â€²))
    (i, j, k) = @index(Global, NTuple)
    if Î³ !== nothing
        @inbounds idenom = inv(sqrt(ÏƒÂ²[j] + Ïµ))
    else
        @inbounds idenom = Î³â€²[j]
    end
    idenomÂ² = idenom^2

    @inbounds xÎ¼ = x[i, j, k] - Î¼[j]

    @inbounds âˆ‚x[i, j, k] = âˆ‚y[i, j, k] * Î³â€²[j]
    @inbounds âˆ‚ÏƒÂ²[i, j, k] = -âˆ‚x[i, j, k] * xÎ¼ * idenomÂ² / 2

    if Î³ !== nothing
        @inbounds âˆ‚Î³[i, j, k] = âˆ‚y[i, j, k] * xÎ¼ * idenom
    end
end
