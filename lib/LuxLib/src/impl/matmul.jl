# Wrappers over Base & LinearAlgebra implementations to use poly algs if needed
matmuladd(A, B, ::Nothing) = matmul(A, B)
function matmuladd(A::AbstractMatrix, B::AbstractVector, bias::AbstractVector)
    return matmuladd(A, expand_batchdim(B), bias)
end
function matmuladd(A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    return matmuladd(internal_operation_mode((A, B, bias)), A, B, bias)
end

function matmuladd(
        ::GenericBroadcastOp, A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    return muladd(A, B, bias)
end
function matmuladd(opmode::AbstractInternalArrayOpMode, A::AbstractMatrix,
        B::AbstractMatrix, bias::AbstractVector)
    if size(A, 2) != size(B, 1)
        throw(DimensionMismatch(lazy"A has shape ($(size(A, 1)), $(size(A, 2))) but B has shape ($(size(B, 1)), $(size(B, 2)))"))
    end
    if length(bias) != size(A, 1)
        throw(DimensionMismatch(lazy"bias has length $(length(bias)) but A has shape ($(size(A, 1)), $(size(A, 2)))"))
    end
    C = similar(A, promote_type(eltype(A), eltype(B), eltype(bias)), size(A, 1), size(B, 2))
    matmuladd!(C, opmode, A, B, bias)
    return C
end

function matmul(A::AbstractMatrix, B::AbstractVector)
    return vec(matmul(A, expand_batchdim(B)))
end
function matmul(A::AbstractMatrix, B::AbstractMatrix)
    if size(A, 2) != size(B, 1)
        throw(DimensionMismatch(lazy"A has shape ($(size(A, 1)), $(size(A, 2))) but B has shape ($(size(B, 1)), $(size(B, 2)))"))
    end
    return matmul(internal_operation_mode((A, B)), A, B)
end

matmul(::GenericBroadcastOp, A::AbstractMatrix, B::AbstractMatrix) = A * B
function matmul(::AbstractInternalArrayOpMode, A::AbstractMatrix, B::AbstractMatrix)
    C = similar(A, promote_type(eltype(A), eltype(B)), size(A, 1), size(B, 2))
    matmul!(C, A, B)
    return C
end

# Slightly higher level. Here we make decisions about which implementation to use
function matmuladd!(C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix, ::Nothing)
    matmul!(C, A, B)
    return
end
function matmuladd!(
        C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    matmuladd!(C, internal_operation_mode((C, A, B, bias)), A, B, bias)
    return
end

function matmuladd!(C::AbstractMatrix, ::AbstractInternalArrayOpMode,
        A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    C .= bias
    mul!(C, A, B, true, true)
    return
end

function matmuladd!(C::AbstractMatrix, ::GPUBroadcastOp{CUDADevice},
        A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    cublasLt_fused_dense!(C, identity, A, B, bias)
    return
end

function matmuladd!(C::AbstractMatrix, ::LoopedArrayOp, A::AbstractMatrix,
        B::AbstractMatrix, bias::AbstractVector)
    if LV.check_args(C, A, B, bias) && fits_in_l2cache(C, A, B, bias)
        matmuladd_loopvec!(C, A, B, bias)
        return
    end
    matmuladd_cpu_fallback!(C, A, B, bias)
    return
end

function matmul!(C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix)
    matmul!(C, internal_operation_mode((C, A, B)), A, B)
    return
end

function matmul!(C::AbstractMatrix, ::AbstractInternalArrayOpMode,
        A::AbstractMatrix, B::AbstractMatrix)
    mul!(C, A, B)
    return
end

function matmul!(C::AbstractMatrix, ::LoopedArrayOp, A::AbstractMatrix, B::AbstractMatrix)
    return matmul_cpu!(C, use_octavian(), explicit_blas_loaded(), A, B)
end

for spl_blas in (True, False)
    @eval begin
        function matmul_cpu!( # Octavian can be used
                C::AbstractMatrix, ::True, ::$(spl_blas),
                A::AbstractMatrix, B::AbstractMatrix)
            if LV.check_args(C, A, B)
                if fits_in_l1cache(C, A, B)
                    matmul_loopvec!(C, A, B, true, false)
                    return
                elseif $(unsafe_known(spl_blas()) ? fits_in_l2cache :
                         fits_in_l3cache)(C, A, B)
                    matmul_octavian!(C, A, B, true, false)
                    return
                end
            end
            matmul_cpu_fallback!(C, A, B, true, false)
            return
        end

        function matmul_cpu!( # Octavian cannot be used
                C::AbstractMatrix, ::False, ::$(spl_blas),
                A::AbstractMatrix, B::AbstractMatrix)
            if LV.check_args(C, A, B)
                if $(unsafe_known(spl_blas()) ? fits_in_l1cache : fits_in_l2cache)(C, A, B)
                    matmul_loopvec!(C, A, B, true, false)
                    return
                end
            end
            matmul_cpu_fallback!(C, A, B, true, false)
            return
        end
    end
end

# Low-Level Matmul implementations -- Either call libraries or implement our own
# We force inlining here to avoid allocations in the inner loops
@inline function matmul_octavian!(
        C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix, Î±::Number, Î²::Number)
    Octavian.matmul!(C, A, B, Î±, Î²)
    return
end

# Best case fallback, we are likely going to hit BLAS
@inline function matmul_cpu_fallback!(C::AbstractMatrix{T}, A::AbstractMatrix{T},
        B::AbstractMatrix{T}, Î±::Number, Î²::Number) where {T}
    matmul_linalg_default!(C, A, B, Î±, Î²)
    return
end

@inline function matmul_cpu_fallback!(C::AbstractMatrix{T}, A::AbstractMatrix{AT},
        B::AbstractMatrix{BT}, Î±::Number, Î²::Number) where {T, AT, BT}
    if LV.check_args(C, A, B)  # Use Octavian if possible. Don't check via `use_octavian()`
        matmul_octavian!(C, A, B, Î±, Î²)
        return
    end
    # Generic fallback is actually quite good starting julia 1.11
    @static if VERSION â‰¥ v"1.11-"
        @warn lazy"Mixed-Precision `matmul_cpu_fallback!` detected and Octavian.jl cannot be used for this set of inputs (C [$(typeof(C))]: A [$(typeof(A))] x B [$(typeof(B))]). Falling back to generic implementation. This may be slow." maxlog=1
        Aâ€², Bâ€² = A, B
    else
        @warn lazy"Mixed-Precision `matmul_cpu_fallback!` detected and Octavian.jl cannot be used for this set of inputs (C [$(typeof(C))]: A [$(typeof(A))] x B [$(typeof(B))]). Converting to common type to to attempt to use BLAS. This may be slow." maxlog=1
        Aâ€², Bâ€² = ofeltype_array(T, A), ofeltype_array(T, B)
    end
    matmul_linalg_default!(C, Aâ€², Bâ€², Î±, Î²)
    return
end

@inline function matmul_linalg_default!(
        C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix, Î±::Number, Î²::Number)
    mul!(C, A, B, Î±, Î²)
    return
end

for serial in (true, false)
    opname = serial ? :serial_matmul_loopvec! : :matmul_loopvec!
    @eval @inline function $opname(
            C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix, Î±::Number, Î²::Number)
        if !iszero(Î²) # Secial case this because Base.FastMath.mul_fast(NaN, false) = NaN
            @turbo thread=$(!serial) for K in indices((C, B), 2), J in indices((C, A), 1)
                Câ±¼â‚– = zero(eltype(C))
                for I in indices((A, B), (2, 1))
                    Câ±¼â‚– += A[J, I] * B[I, K]
                end
                C[J, K] = Î± * Câ±¼â‚– + Î² * C[J, K]
            end
        else
            @turbo thread=$(!serial) for K in indices((C, B), 2), J in indices((C, A), 1)
                Câ±¼â‚– = zero(eltype(C))
                for I in indices((A, B), (2, 1))
                    Câ±¼â‚– += A[J, I] * B[I, K]
                end
                C[J, K] = Î± * Câ±¼â‚–
            end
        end
    end
end

@inline function matmuladd_loopvec!(
        C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    @tturbo for K in indices((C, B), 2), J in indices((C, A), 1)
        Câ±¼â‚– = zero(eltype(C))
        for I in indices((A, B), (2, 1))
            Câ±¼â‚– += A[J, I] * B[I, K]
        end
        C[J, K] = bias[J] + Câ±¼â‚–
    end
    return
end

@inline function matmuladd_cpu_fallback!(
        C::AbstractMatrix, A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    C .= bias
    matmul_cpu_fallback!(C, A, B, true, true)
    return
end

# ChainRules
function CRC.rrule(::typeof(matmul), A::AbstractMatrix, B::AbstractMatrix)
    ğ’«A, ğ’«B = CRC.ProjectTo(A), CRC.ProjectTo(B)
    âˆ‡matmul = @closure Î”â€² -> begin
        Î” = CRC.unthunk(Î”â€²)
        âˆ‚A = CRC.@thunk(ğ’«A(matmul(Î”, B')))
        âˆ‚B = CRC.@thunk(ğ’«B(matmul(A', Î”)))
        return âˆ‚âˆ…, âˆ‚A, âˆ‚B
    end
    return matmul(A, B), âˆ‡matmul
end

function CRC.rrule(
        ::typeof(matmuladd), A::AbstractMatrix, B::AbstractMatrix, bias::AbstractVector)
    ğ’«A, ğ’«B, ğ’«bias = CRC.ProjectTo(A), CRC.ProjectTo(B), CRC.ProjectTo(bias)
    âˆ‡matmuladd = @closure Î”â€² -> begin
        Î” = CRC.unthunk(Î”â€²)
        âˆ‚A = CRC.@thunk(ğ’«A(matmul(Î”, B')))
        âˆ‚B = CRC.@thunk(ğ’«B(matmul(A', Î”)))
        âˆ‚bias = CRC.@thunk(ğ’«bias(âˆ‡bias_add(bias, Î”)))
        return âˆ‚âˆ…, âˆ‚A, âˆ‚B, âˆ‚bias
    end
    return matmuladd(A, B, bias), âˆ‡matmuladd
end

# EnzymeRules
function EnzymeRules.augmented_primal(cfg, ::EnzymeCore.Const{typeof(matmuladd!)},
        ::Type{EnzymeCore.Const{Nothing}}, C::EnzymeCore.Annotation{<:AbstractMatrix},
        opmode::EnzymeCore.Const{<:AbstractInternalArrayOpMode},
        A::EnzymeCore.Annotation{<:AbstractMatrix},
        B::EnzymeCore.Annotation{<:AbstractMatrix},
        bias::EnzymeCore.Annotation{<:AbstractVector})
    A_cache = EnzymeRules.overwritten(cfg)[4] && !(B isa EnzymeCore.Const) &&
              !(C isa EnzymeCore.Const) ? copy(A.val) : nothing
    B_cache = EnzymeRules.overwritten(cfg)[5] && !(A isa EnzymeCore.Const) &&
              !(C isa EnzymeCore.Const) ? copy(B.val) : nothing

    if !(C isa EnzymeCore.DuplicatedNoNeed || C isa EnzymeCore.BatchDuplicatedNoNeed)
        matmuladd!(C.val, opmode.val, A.val, B.val, bias.val)
    end

    return EnzymeRules.AugmentedReturn(nothing, nothing, (A_cache, B_cache))
end

function EnzymeRules.reverse(cfg, ::EnzymeCore.Const{typeof(matmuladd!)},
        ::Type{EnzymeCore.Const{Nothing}}, (A_cache, B_cache),
        C::EnzymeCore.Annotation{<:AbstractMatrix},
        opmode::EnzymeCore.Const{<:AbstractInternalArrayOpMode},
        A::EnzymeCore.Annotation{<:AbstractMatrix},
        B::EnzymeCore.Annotation{<:AbstractMatrix},
        bias::EnzymeCore.Annotation{<:AbstractVector})
    if !(C isa EnzymeCore.Const) && !(B isa EnzymeCore.Const)
        if !EnzymeRules.overwritten(cfg)[4]
            A_cache = A.val
        end
    end

    if !(C isa EnzymeCore.Const) && !(A isa EnzymeCore.Const)
        if !EnzymeRules.overwritten(cfg)[5]
            B_cache = B.val
        end
    end

    âˆ‚Cs = C.dval
    âˆ‚As = A isa EnzymeCore.Const ? âˆ‚Cs : A.dval
    âˆ‚Bs = B isa EnzymeCore.Const ? âˆ‚Cs : B.dval
    âˆ‚bs = bias isa EnzymeCore.Const ? âˆ‚Cs : bias.dval

    if EnzymeRules.width(cfg) == 1
        âˆ‚Cs = (âˆ‚Cs,)
        âˆ‚As = (âˆ‚As,)
        âˆ‚Bs = (âˆ‚Bs,)
        âˆ‚bs = (âˆ‚bs,)
    end

    for (âˆ‚C, âˆ‚A, âˆ‚B, âˆ‚b) in zip(âˆ‚Cs, âˆ‚As, âˆ‚Bs, âˆ‚bs)
        if !(C isa EnzymeCore.Const) && âˆ‚C !== C.val
            if !(bias isa EnzymeCore.Const) && âˆ‚b !== bias.val
                # FIXME: Can we do this without allocating?
                âˆ‚bâ‚ = similar(âˆ‚b)
                sum!(âˆ‚bâ‚, âˆ‚C)
                âˆ‚b .+= âˆ‚bâ‚
            end

            if !(A isa EnzymeCore.Const) && âˆ‚A !== A.val
                # TODO: we don't use our faster matmul here since we lack the 5 arg version
                mul!(âˆ‚A, âˆ‚C, B_cache', true, true)
            end

            if !(B isa EnzymeCore.Const) && âˆ‚B !== B.val
                # TODO: we don't use our faster matmul here since we lack the 5 arg version
                mul!(âˆ‚B, A_cache', âˆ‚C, true, true)
            end

            âˆ‚C .= 0
        end
    end

    return ntuple(Returns(nothing), 5)
end

@enzyme_alternative matmul_octavian! matmul_linalg_default!
@enzyme_alternative serial_matmul_loopvec! matmul_linalg_default!
@enzyme_alternative matmul_loopvec! matmul_linalg_default!

@enzyme_alternative matmuladd_loopvec! matmuladd_cpu_fallback!
