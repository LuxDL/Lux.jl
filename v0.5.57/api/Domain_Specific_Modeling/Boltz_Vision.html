<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Computer Vision Models (Vision API) | Lux.jl Docs</title>
    <meta name="description" content="Documentation for LuxDL Repositories">
    <meta name="generator" content="VitePress v1.2.3">
    <link rel="preload stylesheet" href="/v0.5.57/assets/style.CbF3HklE.css" as="style">
    
    <script type="module" src="/v0.5.57/assets/app.DQlktJ_a.js"></script>
    <link rel="preload" href="/v0.5.57/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/v0.5.57/assets/chunks/framework.BJHWeAXq.js">
    <link rel="modulepreload" href="/v0.5.57/assets/chunks/theme.DB6EBKod.js">
    <link rel="modulepreload" href="/v0.5.57/assets/api_Domain_Specific_Modeling_Boltz_Vision.md.u2MQrVWz.lean.js">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q8GYTEVTZ2"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Q8GYTEVTZ2");</script>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="icon" href="/favicon.ico">
    <link rel="manifest" href="/site.webmanifest">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9a9e638><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c3508ec8></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c3508ec8> Skip to content </a><!--]--><!----><header class="VPNav" data-v-a9a9e638 data-v-f1e365da><div class="VPNavBar has-sidebar top" data-v-f1e365da data-v-40788ea0><div class="wrapper" data-v-40788ea0><div class="container" data-v-40788ea0><div class="title" data-v-40788ea0><div class="VPNavBarTitle has-sidebar" data-v-40788ea0 data-v-28a961f9><a class="title" href="/v0.5.57/" data-v-28a961f9><!--[--><!--]--><!--[--><!--[--><!--[--><img class="VPImage dark logo" src="/v0.5.57/lux-logo-dark.svg" alt data-v-35a7d0b8><!--]--><!--[--><img class="VPImage light logo" src="/v0.5.57/lux-logo.svg" alt data-v-35a7d0b8><!--]--><!--]--><!--]--><span data-v-28a961f9>Lux.jl Docs</span><!--[--><!--]--></a></div></div><div class="content" data-v-40788ea0><div class="content-body" data-v-40788ea0><!--[--><!--]--><div class="VPNavBarSearch search" data-v-40788ea0><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-40788ea0 data-v-492ea56d><span id="main-nav-aria-label" class="visually-hidden" data-v-492ea56d>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/v0.5.57/" tabindex="0" data-v-492ea56d data-v-ed5ac1f6><!--[--><span data-v-ed5ac1f6>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/v0.5.57/introduction" tabindex="0" data-v-492ea56d data-v-ed5ac1f6><!--[--><span data-v-ed5ac1f6>Getting Started</span><!--]--></a><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://lux.csail.mit.edu/benchmarks/" target="_blank" rel="noreferrer" tabindex="0" data-v-492ea56d data-v-ed5ac1f6><!--[--><span data-v-ed5ac1f6>Benchmarks</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/v0.5.57/tutorials/" tabindex="0" data-v-492ea56d data-v-ed5ac1f6><!--[--><span data-v-ed5ac1f6>Tutorials</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/v0.5.57/manual/interface" tabindex="0" data-v-492ea56d data-v-ed5ac1f6><!--[--><span data-v-ed5ac1f6>Manual</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-492ea56d data-v-e5380155><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-e5380155><span class="text" data-v-e5380155><!----><span data-v-e5380155>API</span><span class="vpi-chevron-down text-icon" data-v-e5380155></span></span></button><div class="menu" data-v-e5380155><div class="VPMenu" data-v-e5380155 data-v-97491713><div class="items" data-v-97491713><!--[--><!--[--><div class="VPMenuGroup" data-v-97491713 data-v-48c802d0><p class="title" data-v-48c802d0>Lux</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Lux/layers" data-v-8b74d055><!--[-->Built-In Layers<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Lux/autodiff" data-v-8b74d055><!--[-->Automatic Differentiation<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Lux/utilities" data-v-8b74d055><!--[-->Utilities<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Lux/contrib" data-v-8b74d055><!--[-->Experimental<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Lux/interop" data-v-8b74d055><!--[-->InterOp<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Lux/distributed_utils" data-v-8b74d055><!--[-->DistributedUtils<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-97491713 data-v-48c802d0><p class="title" data-v-48c802d0>Accelerator Support</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Accelerator_Support/LuxDeviceUtils" data-v-8b74d055><!--[-->LuxDeviceUtils<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-97491713 data-v-48c802d0><p class="title" data-v-48c802d0>Building Blocks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Building_Blocks/LuxCore" data-v-8b74d055><!--[-->LuxCore<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Building_Blocks/LuxLib" data-v-8b74d055><!--[-->LuxLib<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Building_Blocks/WeightInitializers" data-v-8b74d055><!--[-->WeightInitializers<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link vp-external-link-icon" href="https://fluxml.ai/NNlib.jl/dev/" target="_blank" rel="noreferrer" data-v-8b74d055><!--[-->NNlib<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link vp-external-link-icon" href="https://fluxml.ai/NNlib.jl/dev/reference/#Activation-Functions" target="_blank" rel="noreferrer" data-v-8b74d055><!--[-->Activation Functions<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-97491713 data-v-48c802d0><p class="title" data-v-48c802d0>Domain Specific Modeling</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Domain_Specific_Modeling/Boltz" data-v-8b74d055><!--[-->Boltz<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-97491713 data-v-48c802d0><p class="title" data-v-48c802d0>Testing Functionality</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-8b74d055><a class="VPLink link" href="/v0.5.57/api/Testing_Functionality/LuxTestUtils" data-v-8b74d055><!--[-->LuxTestUtils<!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-492ea56d data-v-e5380155><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-e5380155><span class="text" data-v-e5380155><!----><span data-v-e5380155>Versions</span><span class="vpi-chevron-down text-icon" data-v-e5380155></span></span></button><div class="menu" data-v-e5380155><div class="VPMenu" data-v-e5380155 data-v-97491713><div class="items" data-v-97491713><!--[--><!--[--><div class="VPMenuLink" data-v-97491713 data-v-8b74d055><a class="VPLink link vp-external-link-icon" href="https://lux.csail.mit.edu/stable" target="_blank" rel="noreferrer" data-v-8b74d055><!--[-->Stable<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-97491713 data-v-8b74d055><a class="VPLink link vp-external-link-icon" href="https://lux.csail.mit.edu/dev" target="_blank" rel="noreferrer" data-v-8b74d055><!--[-->Dev<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-40788ea0 data-v-ead91a81><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-ead91a81 data-v-b79b56d4 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-b79b56d4></span><span class="vpi-moon moon" data-v-b79b56d4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-40788ea0 data-v-164c457f data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/LuxDL/Lux.jl" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-717b8b75><span class="vpi-social-github" /></a><a class="VPSocialLink no-icon" href="https://twitter.com/avikpal1410" aria-label="twitter" target="_blank" rel="noopener" data-v-ee7a9424 data-v-717b8b75><span class="vpi-social-twitter" /></a><a class="VPSocialLink no-icon" href="https://julialang.org/slack/" aria-label="slack" target="_blank" rel="noopener" data-v-ee7a9424 data-v-717b8b75><span class="vpi-social-slack" /></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-40788ea0 data-v-9b536d0b data-v-e5380155><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-e5380155><span class="vpi-more-horizontal icon" data-v-e5380155></span></button><div class="menu" data-v-e5380155><div class="VPMenu" data-v-e5380155 data-v-97491713><!----><!--[--><!--[--><!----><div class="group" data-v-9b536d0b><div class="item appearance" data-v-9b536d0b><p class="label" data-v-9b536d0b>Appearance</p><div class="appearance-action" data-v-9b536d0b><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-9b536d0b data-v-b79b56d4 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-b79b56d4></span><span class="vpi-moon moon" data-v-b79b56d4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-9b536d0b><div class="item social-links" data-v-9b536d0b><div class="VPSocialLinks social-links-list" data-v-9b536d0b data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/LuxDL/Lux.jl" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-717b8b75><span class="vpi-social-github" /></a><a class="VPSocialLink no-icon" href="https://twitter.com/avikpal1410" aria-label="twitter" target="_blank" rel="noopener" data-v-ee7a9424 data-v-717b8b75><span class="vpi-social-twitter" /></a><a class="VPSocialLink no-icon" href="https://julialang.org/slack/" aria-label="slack" target="_blank" rel="noopener" data-v-ee7a9424 data-v-717b8b75><span class="vpi-social-slack" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-40788ea0 data-v-5dea55bf><span class="container" data-v-5dea55bf><span class="top" data-v-5dea55bf></span><span class="middle" data-v-5dea55bf></span><span class="bottom" data-v-5dea55bf></span></span></button></div></div></div></div><div class="divider" data-v-40788ea0><div class="divider-line" data-v-40788ea0></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-a9a9e638 data-v-070ab83d><div class="container" data-v-070ab83d><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-070ab83d><span class="vpi-align-left menu-icon" data-v-070ab83d></span><span class="menu-text" data-v-070ab83d>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-070ab83d data-v-bc9dc845><button data-v-bc9dc845>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-a9a9e638 data-v-ec846e01><div class="curtain" data-v-ec846e01></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-ec846e01><span class="visually-hidden" id="sidebar-aria-label" data-v-ec846e01> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-ec846e01><section class="VPSidebarItem level-0 collapsible" data-v-ec846e01 data-v-2ea20db7><div class="item" role="button" tabindex="0" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><h2 class="text" data-v-2ea20db7>Lux</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-2ea20db7><span class="vpi-chevron-right caret-icon" data-v-2ea20db7></span></div></div><div class="items" data-v-2ea20db7><!--[--><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Lux/layers" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Built-In Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Lux/autodiff" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Automatic Differentiation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Lux/utilities" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Utilities</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Lux/contrib" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Experimental Features</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Lux/interop" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Interoperability</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Lux/distributed_utils" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>DistributedUtils</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-ec846e01><section class="VPSidebarItem level-0 collapsible" data-v-ec846e01 data-v-2ea20db7><div class="item" role="button" tabindex="0" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><h2 class="text" data-v-2ea20db7>Accelerator Support</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-2ea20db7><span class="vpi-chevron-right caret-icon" data-v-2ea20db7></span></div></div><div class="items" data-v-2ea20db7><!--[--><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Accelerator_Support/LuxDeviceUtils" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>LuxDeviceUtils</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-ec846e01><section class="VPSidebarItem level-0 collapsible" data-v-ec846e01 data-v-2ea20db7><div class="item" role="button" tabindex="0" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><h2 class="text" data-v-2ea20db7>Building Blocks</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-2ea20db7><span class="vpi-chevron-right caret-icon" data-v-2ea20db7></span></div></div><div class="items" data-v-2ea20db7><!--[--><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Building_Blocks/LuxCore" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>LuxCore</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Building_Blocks/LuxLib" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>LuxLib</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Building_Blocks/WeightInitializers" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>WeightInitializers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link vp-external-link-icon link" href="https://fluxml.ai/NNlib.jl/dev/" target="_blank" rel="noreferrer" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>NNlib</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link vp-external-link-icon link" href="https://fluxml.ai/NNlib.jl/dev/reference/#Activation-Functions" target="_blank" rel="noreferrer" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Activation Functions</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-ec846e01><section class="VPSidebarItem level-0 collapsible has-active" data-v-ec846e01 data-v-2ea20db7><div class="item" role="button" tabindex="0" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><h2 class="text" data-v-2ea20db7>Domain Specific Modeling</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-2ea20db7><span class="vpi-chevron-right caret-icon" data-v-2ea20db7></span></div></div><div class="items" data-v-2ea20db7><!--[--><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Domain_Specific_Modeling/Boltz" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Boltz</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Domain_Specific_Modeling/Boltz_Vision" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Computer Vision</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Domain_Specific_Modeling/Boltz_Layers" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>Boltz Layers</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-ec846e01><section class="VPSidebarItem level-0 collapsible" data-v-ec846e01 data-v-2ea20db7><div class="item" role="button" tabindex="0" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><h2 class="text" data-v-2ea20db7>Testing Functionality</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-2ea20db7><span class="vpi-chevron-right caret-icon" data-v-2ea20db7></span></div></div><div class="items" data-v-2ea20db7><!--[--><div class="VPSidebarItem level-1 is-link" data-v-2ea20db7 data-v-2ea20db7><div class="item" data-v-2ea20db7><div class="indicator" data-v-2ea20db7></div><a class="VPLink link link" href="/v0.5.57/api/Testing_Functionality/LuxTestUtils" data-v-2ea20db7><!--[--><p class="text" data-v-2ea20db7>LuxTestUtils</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a9a9e638 data-v-91765379><div class="VPDoc has-sidebar has-aside" data-v-91765379 data-v-83890dd9><!--[--><!--]--><div class="container" data-v-83890dd9><div class="aside" data-v-83890dd9><div class="aside-curtain" data-v-83890dd9></div><div class="aside-container" data-v-83890dd9><div class="aside-content" data-v-83890dd9><div class="VPDocAside" data-v-83890dd9 data-v-6d7b3c46><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-6d7b3c46 data-v-b38bf2ff><div class="content" data-v-b38bf2ff><div class="outline-marker" data-v-b38bf2ff></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b38bf2ff>On this page</div><ul class="VPDocOutlineItem root" data-v-b38bf2ff data-v-3f927ebe><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-6d7b3c46></div><!--[--><!--[--><!--[--><!--[--><!--[--><br><h2> Trusted by </h2><a class="enjoyer" href="https://sciml.ai/" target="_blank"><img width="32" height="32" src="https://avatars.githubusercontent.com/u/21238080?v=4"><span><p class="extra-info">Scientific Computing</p><p class="heading">SciML.ai</p><p class="extra-info">Machine Learning</p></span></a><a class="enjoyer" href="https://juliagni.github.io/GeometricMachineLearning.jl/latest/" target="_blank"><img width="32" height="32" src="https://juliagni.github.io/GeometricMachineLearning.jl/latest/assets/logo-dark.png"><span><p class="extra-info">Structure Preserving</p><p class="heading">GeometricML.jl</p><p class="extra-info">Machine Learning</p></span></a><a class="enjoyer" href="https://una-auxme.github.io/MeshGraphNets.jl/dev/" target="_blank"><img width="32" height="32" src="https://raw.githubusercontent.com/una-auxme/MeshGraphNets.jl/main/logo/meshgraphnetsjl_logo.png"><span><p class="extra-info">Physical Systems</p><p class="heading">MeshGraphNets.jl</p><p class="extra-info">Graph Neural Nets</p></span></a><!--]--><!--]--><!--]--><!--]--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-83890dd9><div class="content-container" data-v-83890dd9><!--[--><!--]--><main class="main" data-v-83890dd9><div style="position:relative;" class="vp-doc _v0_5_57_api_Domain_Specific_Modeling_Boltz_Vision" data-v-83890dd9><div><h1 id="Computer-Vision-Models-(Vision-API)" tabindex="-1">Computer Vision Models (<code>Vision</code> API) <a class="header-anchor" href="#Computer-Vision-Models-(Vision-API)" aria-label="Permalink to &quot;Computer Vision Models (`Vision` API) {#Computer-Vision-Models-(Vision-API)}&quot;">​</a></h1><h2 id="Native-Lux-Models" tabindex="-1">Native Lux Models <a class="header-anchor" href="#Native-Lux-Models" aria-label="Permalink to &quot;Native Lux Models {#Native-Lux-Models}&quot;">​</a></h2><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.VGG" href="#Boltz.Vision.VGG">#</a> <b><u>Boltz.Vision.VGG</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">VGG</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(imsize; config, inchannels, batchnorm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, nclasses, fcsize, dropout)</span></span></code></pre></div><p>Create a VGG model [1].</p><p><strong>Arguments</strong></p><ul><li><p><code>imsize</code>: input image width and height as a tuple</p></li><li><p><code>config</code>: the configuration for the convolution layers</p></li><li><p><code>inchannels</code>: number of input channels</p></li><li><p><code>batchnorm</code>: set to <code>true</code> to use batch normalization after each convolution</p></li><li><p><code>nclasses</code>: number of output classes</p></li><li><p><code>fcsize</code>: intermediate fully connected layer size</p></li><li><p><code>dropout</code>: dropout level between fully connected layers</p></li></ul><p><strong>References</strong></p><p>[1] Simonyan, Karen, and Andrew Zisserman. &quot;Very deep convolutional networks for large-scale image recognition.&quot; arXiv preprint arXiv:1409.1556 (2014).</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/vgg.jl#L20-L39" target="_blank" rel="noreferrer">source</a></p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">VGG</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(depth</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; batchnorm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create a VGG model [1] with ImageNet Configuration.</p><p><strong>Arguments</strong></p><ul><li><code>depth::Int</code>: the depth of the VGG model. Choices: {<code>11</code>, <code>13</code>, <code>16</code>, <code>19</code>}.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>batchnorm = false</code>: set to <code>true</code> to use batch normalization after each convolution.</p></li><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] Simonyan, Karen, and Andrew Zisserman. &quot;Very deep convolutional networks for large-scale image recognition.&quot; arXiv preprint arXiv:1409.1556 (2014).</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/vgg.jl#L62-L80" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.VisionTransformer" href="#Boltz.Vision.VisionTransformer">#</a> <b><u>Boltz.Vision.VisionTransformer</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">VisionTransformer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Symbol</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Creates a Vision Transformer model with the specified configuration.</p><p><strong>Arguments</strong></p><ul><li><code>name::Symbol</code>: name of the Vision Transformer model to create. The following models are available:</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/vit.jl#L48-L61" target="_blank" rel="noreferrer">source</a></p></div><br><h2 id="Imported-from-Metalhead.jl" tabindex="-1">Imported from Metalhead.jl <a class="header-anchor" href="#Imported-from-Metalhead.jl" aria-label="Permalink to &quot;Imported from Metalhead.jl {#Imported-from-Metalhead.jl}&quot;">​</a></h2><div class="tip custom-block"><p class="custom-block-title">Tip</p><p>You need to load <code>Flux</code> and <code>Metalhead</code> before using these models.</p></div><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.AlexNet" href="#Boltz.Vision.AlexNet">#</a> <b><u>Boltz.Vision.AlexNet</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AlexNet</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create an AlexNet model [1]</p><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. &quot;Imagenet classification with deep convolutional neural networks.&quot; Advances in neural information processing systems 25 (2012): 1097-1105.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/extensions.jl#L1-L15" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.ConvMixer" href="#Boltz.Vision.ConvMixer">#</a> <b><u>Boltz.Vision.ConvMixer</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ConvMixer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Symbol</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create a ConvMixer model [1].</p><p><strong>Arguments</strong></p><ul><li><code>name::Symbol</code>: The name of the ConvMixer model. Must be one of <code>:base</code>, <code>:small</code>, or <code>:large</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] Zhu, Zhuoyuan, et al. &quot;ConvMixer: A Convolutional Neural Network with Faster Depth-wise Convolutions for Computer Vision.&quot; arXiv preprint arXiv:1911.11907 (2019).</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/extensions.jl#L124-L142" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.DenseNet" href="#Boltz.Vision.DenseNet">#</a> <b><u>Boltz.Vision.DenseNet</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">DenseNet</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(depth</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create a DenseNet model [1].</p><p><strong>Arguments</strong></p><ul><li><code>depth::Int</code>: The depth of the DenseNet model. Must be one of 121, 161, 169, or 201.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger. &quot;Densely connected convolutional networks.&quot; Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/extensions.jl#L77-L95" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.GoogLeNet" href="#Boltz.Vision.GoogLeNet">#</a> <b><u>Boltz.Vision.GoogLeNet</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GoogLeNet</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create a GoogLeNet model [1].</p><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. &quot;Going deeper with convolutions.&quot; Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/extensions.jl#L59-L74" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.MobileNet" href="#Boltz.Vision.MobileNet">#</a> <b><u>Boltz.Vision.MobileNet</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MobileNet</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Symbol</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create a MobileNet model [1, 2, 3].</p><p><strong>Arguments</strong></p><ul><li><code>name::Symbol</code>: The name of the MobileNet model. Must be one of <code>:v1</code>, <code>:v2</code>, <code>:v3_small</code>, or <code>:v3_large</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] Howard, Andrew G., et al. &quot;Mobilenets: Efficient convolutional neural networks for mobile vision applications.&quot; arXiv preprint arXiv:1704.04861 (2017). [2] Sandler, Mark, et al. &quot;Mobilenetv2: Inverted residuals and linear bottlenecks.&quot; Proceedings of the IEEE conference on computer vision and pattern recognition. 2018. [3] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam. &quot;Searching for MobileNetV3.&quot; arXiv preprint arXiv:1905.02244. 2019.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/extensions.jl#L98-L121" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.ResNet" href="#Boltz.Vision.ResNet">#</a> <b><u>Boltz.Vision.ResNet</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ResNet</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(depth</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create a ResNet model [1].</p><p><strong>Arguments</strong></p><ul><li><code>depth::Int</code>: The depth of the ResNet model. Must be one of 18, 34, 50, 101, or 152.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] He, Kaiming, et al. &quot;Deep residual learning for image recognition.&quot; Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/extensions.jl#L18-L35" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.Vision.ResNeXt" href="#Boltz.Vision.ResNeXt">#</a> <b><u>Boltz.Vision.ResNeXt</u></b> — <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ResNeXt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(depth</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Create a ResNeXt model [1].</p><p><strong>Arguments</strong></p><ul><li><code>depth::Int</code>: The depth of the ResNeXt model. Must be one of 50, 101, or 152.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>pretrained::Bool=false</code>: If <code>true</code>, returns a pretrained model.</p></li><li><p><code>rng::Union{Nothing, AbstractRNG}=nothing</code>: Random number generator.</p></li><li><p><code>seed::Int=0</code>: Random seed.</p></li><li><p><code>initialized::Val{Bool}=Val(true)</code>: If <code>Val(true)</code>, returns <code>(model, parameters, states)</code>, otherwise just <code>model</code>.</p></li></ul><p><strong>References</strong></p><p>[1] Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He, Ross Gorshick, and Piotr Dollár. &quot;Aggregated residual transformations for deep neural networks.&quot; Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.9/src/vision/extensions.jl#L38-L56" target="_blank" rel="noreferrer">source</a></p></div><br><h2 id="Pretrained-Models" tabindex="-1">Pretrained Models <a class="header-anchor" href="#Pretrained-Models" aria-label="Permalink to &quot;Pretrained Models {#Pretrained-Models}&quot;">​</a></h2><div class="tip custom-block"><p class="custom-block-title">Tip</p><p>Pass <code>pretrained=true</code> to the model constructor to load the pretrained weights.</p></div><table tabindex="0"><thead><tr><th style="text-align:left;">MODEL</th><th style="text-align:center;">TOP 1 ACCURACY (%)</th><th style="text-align:center;">TOP 5 ACCURACY (%)</th></tr></thead><tbody><tr><td style="text-align:left;"><code>AlexNet()</code></td><td style="text-align:center;">54.48</td><td style="text-align:center;">77.72</td></tr><tr><td style="text-align:left;"><code>VGG(11)</code></td><td style="text-align:center;">67.35</td><td style="text-align:center;">87.91</td></tr><tr><td style="text-align:left;"><code>VGG(13)</code></td><td style="text-align:center;">68.40</td><td style="text-align:center;">88.48</td></tr><tr><td style="text-align:left;"><code>VGG(16)</code></td><td style="text-align:center;">70.24</td><td style="text-align:center;">89.80</td></tr><tr><td style="text-align:left;"><code>VGG(19)</code></td><td style="text-align:center;">71.09</td><td style="text-align:center;">90.27</td></tr><tr><td style="text-align:left;"><code>VGG(11; batchnorm=true)</code></td><td style="text-align:center;">69.09</td><td style="text-align:center;">88.94</td></tr><tr><td style="text-align:left;"><code>VGG(13; batchnorm=true)</code></td><td style="text-align:center;">69.66</td><td style="text-align:center;">89.49</td></tr><tr><td style="text-align:left;"><code>VGG(16; batchnorm=true)</code></td><td style="text-align:center;">72.11</td><td style="text-align:center;">91.02</td></tr><tr><td style="text-align:left;"><code>VGG(19; batchnorm=true)</code></td><td style="text-align:center;">72.95</td><td style="text-align:center;">91.32</td></tr></tbody></table><h3 id="preprocessing" tabindex="-1">Preprocessing <a class="header-anchor" href="#preprocessing" aria-label="Permalink to &quot;Preprocessing&quot;">​</a></h3><p>All the pretrained models require that the images be normalized with the parameters <code>mean = [0.485f0, 0.456f0, 0.406f0]</code> and <code>std = [0.229f0, 0.224f0, 0.225f0]</code>.</p></div></div></main><footer class="VPDocFooter" data-v-83890dd9 data-v-b88cabfa><!--[--><!--]--><div class="edit-info" data-v-b88cabfa><div class="edit-link" data-v-b88cabfa><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/LuxDL/Lux.jl/edit/main/docs/src/api/Domain_Specific_Modeling/Boltz_Vision.md" target="_blank" rel="noreferrer" data-v-b88cabfa><!--[--><span class="vpi-square-pen edit-link-icon" data-v-b88cabfa></span> Edit this page on GitHub<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-b88cabfa><span class="visually-hidden" id="doc-footer-aria-label" data-v-b88cabfa>Pager</span><div class="pager" data-v-b88cabfa><a class="VPLink link pager-link prev" href="/v0.5.57/api/Domain_Specific_Modeling/Boltz" data-v-b88cabfa><!--[--><span class="desc" data-v-b88cabfa>Previous page</span><span class="title" data-v-b88cabfa>Boltz</span><!--]--></a></div><div class="pager" data-v-b88cabfa><a class="VPLink link pager-link next" href="/v0.5.57/api/Domain_Specific_Modeling/Boltz_Layers" data-v-b88cabfa><!--[--><span class="desc" data-v-b88cabfa>Next page</span><span class="title" data-v-b88cabfa>Boltz Layers</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-a9a9e638 data-v-c970a860><div class="container" data-v-c970a860><p class="message" data-v-c970a860>Made with <a href="https://documenter.juliadocs.org/stable/" target="_blank"><strong>Documenter.jl</strong></a>, <a href="https://vitepress.dev" target="_blank"><strong>VitePress</strong></a> and <a href="https://luxdl.github.io/DocumenterVitepress.jl/stable" target="_blank"><strong>DocumenterVitepress.jl</strong></a><br>Released under the MIT License. Powered by the <a href="https://www.julialang.org">Julia Programming Language</a>.<br></p><p class="copyright" data-v-c970a860>© Copyright 2024 Avik Pal.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api_domain_specific_modeling_boltz_private.md\":\"CPzWhOWO\",\"api_domain_specific_modeling_boltz.md\":\"CQuwKUaT\",\"api_lux_distributed_utils.md\":\"Dwhq6_jQ\",\"introduction_resources.md\":\"8xWtDGWR\",\"manual_distributed_utils.md\":\"Cq_QHpGG\",\"ecosystem.md\":\"ZPcuvOtk\",\"api_lux_interop.md\":\"DXM6eq-W\",\"manual_gpu_management.md\":\"D2H_vu-5\",\"index.md\":\"tY08jE4j\",\"introduction_overview.md\":\"CKU7YWsD\",\"api_testing_functionality_luxtestutils.md\":\"CH74Nwl_\",\"manual_freezing_model_parameters.md\":\"CHytTkbB\",\"introduction_citation.md\":\"CGyx3SEw\",\"api_accelerator_support_luxdeviceutils.md\":\"D8VvCtkS\",\"manual_debugging.md\":\"Bks7UNr8\",\"manual_weight_initializers.md\":\"Cz1upPzq\",\"api_lux_contrib.md\":\"D8BiBLu6\",\"introduction_index.md\":\"BNS9I8Fu\",\"api_building_blocks_weightinitializers.md\":\"BFksMSpJ\",\"api_lux_autodiff.md\":\"DPQtrLEC\",\"api_building_blocks_luxcore.md\":\"CjFT4YmR\",\"api_domain_specific_modeling_boltz_vision.md\":\"u2MQrVWz\",\"manual_dispatch_custom_input.md\":\"D8V0FGnS\",\"manual_migrate_from_flux.md\":\"2n21wDE_\",\"manual_interface.md\":\"D8Qjg-v3\",\"api_building_blocks_luxlib.md\":\"BllVBB-P\",\"manual_nested_autodiff.md\":\"BPHzu-7j\",\"api_domain_specific_modeling_boltz_layers.md\":\"BV1fGyup\",\"tutorials_beginner_1_basics.md\":\"CDysYjWA\",\"tutorials_index.md\":\"BbtP_SIW\",\"tutorials_beginner_4_simplechains.md\":\"BuLPV5Tb\",\"tutorials_beginner_3_simplernn.md\":\"DczGoFz3\",\"tutorials_intermediate_3_hypernet.md\":\"Yx9-jblz\",\"tutorials_intermediate_1_neuralode.md\":\"DKL0yv0E\",\"api_lux_utilities.md\":\"C1WVZCnD\",\"tutorials_beginner_2_polynomialfitting.md\":\"CaVD2fR-\",\"tutorials_advanced_2_symbolicoptimalcontrol.md\":\"E4DbCg-E\",\"api_lux_layers.md\":\"BFNx5uMh\",\"tutorials_intermediate_2_bayesiannn.md\":\"Bzs5PjoY\",\"tutorials_advanced_1_gravitationalwaveform.md\":\"OuVaA0KM\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Lux.jl Docs\",\"description\":\"Documentation for LuxDL Repositories\",\"base\":\"/v0.5.57/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":\"deep\",\"logo\":{\"light\":\"/lux-logo.svg\",\"dark\":\"/lux-logo-dark.svg\"},\"search\":{\"provider\":\"local\",\"options\":{\"detailedView\":true}},\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Getting Started\",\"link\":\"/introduction\"},{\"text\":\"Benchmarks\",\"link\":\"https://lux.csail.mit.edu/benchmarks/\"},{\"text\":\"Tutorials\",\"link\":\"/tutorials/\"},{\"text\":\"Manual\",\"link\":\"/manual/interface\"},{\"text\":\"API\",\"items\":[{\"text\":\"Lux\",\"items\":[{\"text\":\"Built-In Layers\",\"link\":\"/api/Lux/layers\"},{\"text\":\"Automatic Differentiation\",\"link\":\"/api/Lux/autodiff\"},{\"text\":\"Utilities\",\"link\":\"/api/Lux/utilities\"},{\"text\":\"Experimental\",\"link\":\"/api/Lux/contrib\"},{\"text\":\"InterOp\",\"link\":\"/api/Lux/interop\"},{\"text\":\"DistributedUtils\",\"link\":\"/api/Lux/distributed_utils\"}]},{\"text\":\"Accelerator Support\",\"items\":[{\"text\":\"LuxDeviceUtils\",\"link\":\"/api/Accelerator_Support/LuxDeviceUtils\"}]},{\"text\":\"Building Blocks\",\"items\":[{\"text\":\"LuxCore\",\"link\":\"/api/Building_Blocks/LuxCore\"},{\"text\":\"LuxLib\",\"link\":\"/api/Building_Blocks/LuxLib\"},{\"text\":\"WeightInitializers\",\"link\":\"/api/Building_Blocks/WeightInitializers\"},{\"text\":\"NNlib\",\"link\":\"https://fluxml.ai/NNlib.jl/dev/\"},{\"text\":\"Activation Functions\",\"link\":\"https://fluxml.ai/NNlib.jl/dev/reference/#Activation-Functions\"}]},{\"text\":\"Domain Specific Modeling\",\"items\":[{\"text\":\"Boltz\",\"link\":\"/api/Domain_Specific_Modeling/Boltz\"}]},{\"text\":\"Testing Functionality\",\"items\":[{\"text\":\"LuxTestUtils\",\"link\":\"/api/Testing_Functionality/LuxTestUtils\"}]}]},{\"text\":\"Versions\",\"items\":[{\"text\":\"Stable\",\"link\":\"https://lux.csail.mit.edu/stable\"},{\"text\":\"Dev\",\"link\":\"https://lux.csail.mit.edu/dev\"}]}],\"sidebar\":{\"/introduction/\":{\"text\":\"Getting Started\",\"collapsed\":false,\"items\":[{\"text\":\"Introduction\",\"link\":\"/introduction\"},{\"text\":\"Overview\",\"link\":\"/introduction/overview\"},{\"text\":\"Resources\",\"link\":\"/introduction/resources\"},{\"text\":\"Citation\",\"link\":\"/introduction/citation\"}]},\"/tutorials/\":{\"text\":\"Tutorials\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/tutorials/\"},{\"text\":\"Beginner\",\"collapsed\":false,\"items\":[{\"text\":\"Julia & Lux for the Uninitiated\",\"link\":\"/tutorials/beginner/1_Basics\"},{\"text\":\"Fitting a Polynomial using MLP\",\"link\":\"/tutorials/beginner/2_PolynomialFitting\"},{\"text\":\"Training a Simple LSTM\",\"link\":\"/tutorials/beginner/3_SimpleRNN\"},{\"text\":\"MNIST Classification with SimpleChains\",\"link\":\"/tutorials/beginner/4_SimpleChains\"}]},{\"text\":\"Intermediate\",\"collapsed\":false,\"items\":[{\"text\":\"MNIST Classification using Neural ODEs\",\"link\":\"/tutorials/intermediate/1_NeuralODE\"},{\"text\":\"Bayesian Neural Network\",\"link\":\"/tutorials/intermediate/2_BayesianNN\"},{\"text\":\"Training a HyperNetwork on MNIST and FashionMNIST\",\"link\":\"/tutorials/intermediate/3_HyperNet\"}]},{\"text\":\"Advanced\",\"collapsed\":false,\"items\":[{\"text\":\"Training a Neural ODE to Model Gravitational Waveforms\",\"link\":\"/tutorials/advanced/1_GravitationalWaveForm\"},{\"text\":\"Solving Optimal Control Problems with Symbolic UDEs\",\"link\":\"/tutorials/advanced/2_SymbolicOptimalControl\"}]},{\"text\":\"Large Models\",\"collapsed\":true,\"items\":[{\"text\":\"Training Image Classification Models on ImageNet with Distributed Data Parallel Training\",\"link\":\"https://github.com/LuxDL/Lux.jl/tree/main/examples/ImageNet\"},{\"text\":\"Training a DDIM (Diffusion Model) for Image Generation\",\"link\":\"https://github.com/LuxDL/Lux.jl/tree/main/examples/DDIM\"},{\"text\":\"ConvMixer on CIFAR-10\",\"link\":\"https://github.com/LuxDL/Lux.jl/tree/main/examples/ConvMixer\"}]},{\"text\":\"3rd Party Tutorials\",\"collapsed\":true,\"items\":[{\"text\":\"PINNs (NeuralPDE.jl)\",\"link\":\"https://docs.sciml.ai/NeuralPDE/stable/tutorials/pdesystem/\"},{\"text\":\"UDEs (SciMLSensitivity.jl)\",\"link\":\"https://docs.sciml.ai/SciMLSensitivity/stable/tutorials/data_parallel/\"},{\"text\":\"Neural DEs (DiffEqFlux.jl)\",\"link\":\"https://docs.sciml.ai/DiffEqFlux/stable/examples/neural_ode/\"},{\"text\":\"DEQs (DeepEquilibriumNetworks.jl)\",\"link\":\"https://docs.sciml.ai/DeepEquilibriumNetworks/stable/tutorials/basic_mnist_deq/\"},{\"text\":\"Medical Image Segmentation\",\"link\":\"https://github.com/Dale-Black/ComputerVisionTutorials.jl/\"},{\"text\":\"Neural closure models\",\"link\":\"https://github.com/agdestein/NeuralClosureTutorials/\"}]}]},\"/manual/\":{\"text\":\"Manual\",\"collapsed\":false,\"items\":[{\"text\":\"Lux Interface\",\"link\":\"/manual/interface\"},{\"text\":\"Debugging Lux Models\",\"link\":\"/manual/debugging\"},{\"text\":\"Dispatching on Custom Input Types\",\"link\":\"/manual/dispatch_custom_input\"},{\"text\":\"Freezing Model Parameters\",\"link\":\"/manual/freezing_model_parameters\"},{\"text\":\"GPU Management\",\"link\":\"/manual/gpu_management\"},{\"text\":\"Migrating from Flux to Lux\",\"link\":\"/manual/migrate_from_flux\"},{\"text\":\"Initializing Weights\",\"link\":\"/manual/weight_initializers\"},{\"text\":\"Distributed Data Parallel Training\",\"link\":\"/manual/distributed_utils\"},{\"text\":\"Nested Automatic Differentiation\",\"link\":\"/manual/nested_autodiff\"}]},\"/api/\":{\"text\":\"API Reference\",\"collapsed\":false,\"items\":[{\"text\":\"Lux\",\"collapsed\":false,\"items\":[{\"text\":\"Built-In Layers\",\"link\":\"/api/Lux/layers\"},{\"text\":\"Automatic Differentiation\",\"link\":\"/api/Lux/autodiff\"},{\"text\":\"Utilities\",\"link\":\"/api/Lux/utilities\"},{\"text\":\"Experimental Features\",\"link\":\"/api/Lux/contrib\"},{\"text\":\"Interoperability\",\"link\":\"/api/Lux/interop\"},{\"text\":\"DistributedUtils\",\"link\":\"/api/Lux/distributed_utils\"}]},{\"text\":\"Accelerator Support\",\"collapsed\":false,\"items\":[{\"text\":\"LuxDeviceUtils\",\"link\":\"/api/Accelerator_Support/LuxDeviceUtils\"}]},{\"text\":\"Building Blocks\",\"collapsed\":false,\"items\":[{\"text\":\"LuxCore\",\"link\":\"/api/Building_Blocks/LuxCore\"},{\"text\":\"LuxLib\",\"link\":\"/api/Building_Blocks/LuxLib\"},{\"text\":\"WeightInitializers\",\"link\":\"/api/Building_Blocks/WeightInitializers\"},{\"text\":\"NNlib\",\"link\":\"https://fluxml.ai/NNlib.jl/dev/\"},{\"text\":\"Activation Functions\",\"link\":\"https://fluxml.ai/NNlib.jl/dev/reference/#Activation-Functions\"}]},{\"text\":\"Domain Specific Modeling\",\"collapsed\":false,\"items\":[{\"text\":\"Boltz\",\"link\":\"/api/Domain_Specific_Modeling/Boltz\"},{\"text\":\"Computer Vision\",\"link\":\"/api/Domain_Specific_Modeling/Boltz_Vision\"},{\"text\":\"Boltz Layers\",\"link\":\"/api/Domain_Specific_Modeling/Boltz_Layers\"}]},{\"text\":\"Testing Functionality\",\"collapsed\":false,\"items\":[{\"text\":\"LuxTestUtils\",\"link\":\"/api/Testing_Functionality/LuxTestUtils\"}]}]}},\"editLink\":{\"pattern\":\"https://github.com/LuxDL/Lux.jl/edit/main/docs/src/:path\",\"text\":\"Edit this page on GitHub\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/LuxDL/Lux.jl\"},{\"icon\":\"twitter\",\"link\":\"https://twitter.com/avikpal1410\"},{\"icon\":\"slack\",\"link\":\"https://julialang.org/slack/\"}],\"footer\":{\"message\":\"Made with <a href=\\\"https://documenter.juliadocs.org/stable/\\\" target=\\\"_blank\\\"><strong>Documenter.jl</strong></a>, <a href=\\\"https://vitepress.dev\\\" target=\\\"_blank\\\"><strong>VitePress</strong></a> and <a href=\\\"https://luxdl.github.io/DocumenterVitepress.jl/stable\\\" target=\\\"_blank\\\"><strong>DocumenterVitepress.jl</strong></a><br>Released under the MIT License. Powered by the <a href=\\\"https://www.julialang.org\\\">Julia Programming Language</a>.<br>\",\"copyright\":\"© Copyright 2024 Avik Pal.\"},\"lastUpdated\":{\"text\":\"Updated at\",\"formatOptions\":{\"dateStyle\":\"full\",\"timeStyle\":\"medium\"}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>