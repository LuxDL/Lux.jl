{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fitting a Polynomial using MLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial we will fit a MultiLayer Perceptron (MLP) on data generated from a\n",
    "polynomial."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Package Imports"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Lux, ADTypes, Optimisers, Printf, Random, Reactant, Statistics, CairoMakie"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate 128 datapoints from the polynomial $y = x^2 - 2x$."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function generate_data(rng::AbstractRNG)\n",
    "    x = reshape(collect(range(-2.0f0, 2.0f0, 128)), (1, 128))\n",
    "    poly_coeffs = (0, -2, 1)\n",
    "    y = evalpoly.(x, (poly_coeffs,))\n",
    "    # add some noise to simulate real-world conditions\n",
    "    y .+= randn(rng, Float32, (1, 128)) .* 0.1f0\n",
    "    return (x, y)\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize the random number generator and fetch the dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rng = MersenneTwister()\n",
    "Random.seed!(rng, 12345)\n",
    "\n",
    "(x, y) = generate_data(rng)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visualize the dataset"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "begin\n",
    "    fig = Figure()\n",
    "    ax = CairoMakie.Axis(fig[1, 1]; xlabel=\"x\", ylabel=\"y\")\n",
    "\n",
    "    l = lines!(ax, x[1, :], x -> evalpoly(x, (0, -2, 1)); linewidth=3, color=:blue)\n",
    "    s = scatter!(\n",
    "        ax,\n",
    "        x[1, :],\n",
    "        y[1, :];\n",
    "        markersize=12,\n",
    "        alpha=0.5,\n",
    "        color=:orange,\n",
    "        strokecolor=:black,\n",
    "        strokewidth=2,\n",
    "    )\n",
    "\n",
    "    axislegend(ax, [l, s], [\"True Quadratic Function\", \"Data Points\"])\n",
    "\n",
    "    fig\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this problem, you should not be using a neural network. But let's still do that!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = Chain(Dense(1 => 16, relu), Dense(16 => 1))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use Adam from [Optimisers.jl](https://fluxml.ai/Optimisers.jl)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "opt = Adam(0.03f0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the `Training` API so we need to ensure that our loss function takes 4\n",
    "inputs -- model, parameters, states and data. The function must return 3 values -- loss,\n",
    "updated_state, and any computed statistics. This is already satisfied by the loss\n",
    "functions provided by Lux."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "const loss_function = MSELoss()\n",
    "\n",
    "const cdev = cpu_device()\n",
    "const xdev = reactant_device()\n",
    "\n",
    "ps, st = xdev(Lux.setup(rng, model))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we will create a `Training.TrainState` which is essentially a\n",
    "convenience wrapper over parameters, states and optimizer states."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tstate = Training.TrainState(model, ps, st, opt)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will use Enzyme (Reactant) for our AD requirements."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "vjp_rule = AutoEnzyme()\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally the training loop."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function main(tstate::Training.TrainState, vjp, data, epochs)\n",
    "    data = xdev(data)\n",
    "    for epoch in 1:epochs\n",
    "        _, loss, _, tstate = Training.single_train_step!(vjp, loss_function, data, tstate)\n",
    "        if epoch % 50 == 1 || epoch == epochs\n",
    "            @printf \"Epoch: %3d \\t Loss: %.5g\\n\" epoch loss\n",
    "        end\n",
    "    end\n",
    "    return tstate\n",
    "end\n",
    "\n",
    "tstate = main(tstate, vjp_rule, (x, y), 250)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we are using Reactant, we need to compile the model before we can use it."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "forward_pass = Reactant.with_config(;\n",
    "    dot_general_precision=PrecisionConfig.HIGH,\n",
    "    convolution_precision=PrecisionConfig.HIGH,\n",
    ") do\n",
    "    @compile Lux.apply(tstate.model, xdev(x), tstate.parameters, Lux.testmode(tstate.states))\n",
    "end\n",
    "\n",
    "y_pred = cdev(\n",
    "    first(\n",
    "        forward_pass(tstate.model, xdev(x), tstate.parameters, Lux.testmode(tstate.states))\n",
    "    ),\n",
    ")\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot the results"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "begin\n",
    "    fig = Figure()\n",
    "    ax = CairoMakie.Axis(fig[1, 1]; xlabel=\"x\", ylabel=\"y\")\n",
    "\n",
    "    l = lines!(ax, x[1, :], x -> evalpoly(x, (0, -2, 1)); linewidth=3)\n",
    "    s1 = scatter!(\n",
    "        ax,\n",
    "        x[1, :],\n",
    "        y[1, :];\n",
    "        markersize=12,\n",
    "        alpha=0.5,\n",
    "        color=:orange,\n",
    "        strokecolor=:black,\n",
    "        strokewidth=2,\n",
    "    )\n",
    "    s2 = scatter!(\n",
    "        ax,\n",
    "        x[1, :],\n",
    "        y_pred[1, :];\n",
    "        markersize=12,\n",
    "        alpha=0.5,\n",
    "        color=:green,\n",
    "        strokecolor=:black,\n",
    "        strokewidth=2,\n",
    "    )\n",
    "\n",
    "    axislegend(ax, [l, s1, s2], [\"True Quadratic Function\", \"Actual Data\", \"Predictions\"])\n",
    "\n",
    "    fig\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.7",
   "language": "julia"
  }
 },
 "nbformat": 4
}