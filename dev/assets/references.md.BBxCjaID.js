import{_ as i,C as o,o as r,c as t,j as n,a as l,E as s,al as m}from"./chunks/framework.kzDw1Qip.js";const y=JSON.parse('{"title":"References","description":"","frontmatter":{},"headers":[],"relativePath":"references.md","filePath":"references.md","lastUpdated":null}'),d={name:"references.md"};function p(c,e,f,u,g,v){const a=o("CopyOrDownloadAsMarkdownButtons");return r(),t("div",null,[e[0]||(e[0]=n("div",{style:{display:"none"},hidden:"true","aria-hidden":"true"},"Are you an LLM? You can read better optimized documentation at /dev/references.md for this page in Markdown format",-1)),e[1]||(e[1]=n("h1",{id:"References",tabindex:"-1"},[l("References "),n("a",{class:"header-anchor",href:"#References","aria-label":'Permalink to "References {#References}"'},"​")],-1)),s(a),e[2]||(e[2]=m('<ol><li><p><a id="vaswani2017attention"></a> A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser and I. Polosukhin. <em>Attention is all you need</em>. Advances in neural information processing systems <strong>30</strong> (2017).</p></li><li><p><a id="su2024roformer"></a> J. Su, M. Ahmed, Y. Lu, S. Pan, W. Bo and Y. Liu. <em>Roformer: Enhanced transformer with rotary position embedding</em>. Neurocomputing <strong>568</strong>, 127063 (2024).</p></li><li><p><a id="goodfellow2013maxout"></a> I. Goodfellow, D. Warde-Farley, M. Mirza, A. Courville and Y. Bengio. <em>Maxout networks</em>. In: <em>International conference on machine learning</em> (PMLR, 2013); pp. 1319–1327.</p></li><li><p><a id="ulyanov2016instance"></a> D. Ulyanov, A. Vedaldi and V. Lempitsky. <em>Instance normalization: The missing ingredient for fast stylization</em>, arXiv preprint arXiv:1607.08022 (2016).</p></li><li><p><a id="lin2017focal"></a> T.-Y. Lin, P. Goyal, R. Girshick, K. He and P. Dollár. <em>Focal loss for dense object detection</em>. In: <em>Proceedings of the IEEE international conference on computer vision</em> (2017); pp. 2980–2988.</p></li><li><p><a id="milletari2016v"></a> F. Milletari, N. Navab and S.-A. Ahmadi. <em>V-net: Fully convolutional neural networks for volumetric medical image segmentation</em>. In: <em>2016 fourth international conference on 3D vision (3DV)</em> (Ieee, 2016); pp. 565–571.</p></li><li><p><a id="hadsell2006dimensionality"></a> R. Hadsell, S. Chopra and Y. LeCun. <em>Dimensionality reduction by learning an invariant mapping</em>. In: <em>2006 IEEE computer society conference on computer vision and pattern recognition (CVPR&#39;06)</em>, Vol. 2 (IEEE, 2006); pp. 1735–1742.</p></li><li><p><a id="klambauer2017self"></a> G. Klambauer, T. Unterthiner, A. Mayr and S. Hochreiter. <em>Self-normalizing neural networks</em>. Advances in neural information processing systems <strong>30</strong> (2017).</p></li><li><p><a id="srivastava2014dropout"></a> N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever and R. Salakhutdinov. <em>Dropout: a simple way to prevent neural networks from overfitting</em>. The journal of machine learning research <strong>15</strong>, 1929–1958 (2014).</p></li><li><p><a id="ioffe2015batch"></a> S. Ioffe and C. Szegedy. <em>Batch normalization: Accelerating deep network training by reducing internal covariate shift</em>. In: <em>International conference on machine learning</em> (pmlr, 2015); pp. 448–456.</p></li><li><p><a id="wu2018group"></a> Y. Wu and K. He. <em>Group normalization</em>. In: <em>Proceedings of the European conference on computer vision (ECCV)</em> (2018); pp. 3–19.</p></li><li><p><a id="ba2016layer"></a> J. L. Ba, J. R. Kiros and G. E. Hinton. <em>Layer normalization</em>, arXiv preprint arXiv:1607.06450 (2016).</p></li></ol>',1))])}const k=i(d,[["render",p]]);export{y as __pageData,k as default};
