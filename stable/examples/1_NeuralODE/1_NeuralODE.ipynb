{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST Classification using Neural ODEs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To understand Neural ODEs, users should look up\n",
    "[these lecture notes](https://book.sciml.ai/notes/11-Differentiable_Programming_and_Neural_Differential_Equations/).\n",
    "We recommend users to directly use\n",
    "[DiffEqFlux.jl](https://docs.sciml.ai/DiffEqFlux/stable/), instead of implementing\n",
    "Neural ODEs from scratch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Package Imports"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Lux,\n",
    "    ComponentArrays,\n",
    "    SciMLSensitivity,\n",
    "    LuxCUDA,\n",
    "    Optimisers,\n",
    "    OrdinaryDiffEqTsit5,\n",
    "    Random,\n",
    "    Statistics,\n",
    "    Zygote,\n",
    "    OneHotArrays,\n",
    "    InteractiveUtils,\n",
    "    Printf\n",
    "using MLDatasets: MNIST\n",
    "using MLUtils: DataLoader, splitobs\n",
    "\n",
    "CUDA.allowscalar(false)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading MNIST"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function loadmnist(batchsize, train_split)\n",
    "    # Load MNIST: Only 1500 for demonstration purposes\n",
    "    N = parse(Bool, get(ENV, \"CI\", \"false\")) ? 1500 : nothing\n",
    "    dataset = MNIST(; split=:train)\n",
    "    if N !== nothing\n",
    "        imgs = dataset.features[:, :, 1:N]\n",
    "        labels_raw = dataset.targets[1:N]\n",
    "    else\n",
    "        imgs = dataset.features\n",
    "        labels_raw = dataset.targets\n",
    "    end\n",
    "\n",
    "    # Process images into (H,W,C,BS) batches\n",
    "    x_data = Float32.(reshape(imgs, size(imgs, 1), size(imgs, 2), 1, size(imgs, 3)))\n",
    "    y_data = onehotbatch(labels_raw, 0:9)\n",
    "    (x_train, y_train), (x_test, y_test) = splitobs((x_data, y_data); at=train_split)\n",
    "\n",
    "    return (\n",
    "        # Use DataLoader to automatically minibatch and shuffle the data\n",
    "        DataLoader(collect.((x_train, y_train)); batchsize, shuffle=true),\n",
    "        # Don't shuffle the test data\n",
    "        DataLoader(collect.((x_test, y_test)); batchsize, shuffle=false),\n",
    "    )\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the Neural ODE Layer\n",
    "\n",
    "First we will use the `@compact` macro to define the Neural ODE Layer."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function NeuralODECompact(\n",
    "    model::Lux.AbstractLuxLayer; solver=Tsit5(), tspan=(0.0f0, 1.0f0), kwargs...\n",
    ")\n",
    "    return @compact(; model, solver, tspan, kwargs...) do x, p\n",
    "        dudt(u, p, t) = vec(model(reshape(u, size(x)), p))\n",
    "        # Note the `p.model` here\n",
    "        prob = ODEProblem(ODEFunction{false}(dudt), vec(x), tspan, p.model)\n",
    "        @return solve(prob, solver; kwargs...)\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We recommend using the compact macro for creating custom layers. The below implementation\n",
    "exists mostly for historical reasons when `@compact` was not part of the stable API. Also,\n",
    "it helps users understand how the layer interface of Lux works."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The NeuralODE is a ContainerLayer, which stores a `model`. The parameters and states of\n",
    "the NeuralODE are same as those of the underlying model."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct NeuralODE{M<:Lux.AbstractLuxLayer,So,T,K} <: Lux.AbstractLuxWrapperLayer{:model}\n",
    "    model::M\n",
    "    solver::So\n",
    "    tspan::T\n",
    "    kwargs::K\n",
    "end\n",
    "\n",
    "function NeuralODE(\n",
    "    model::Lux.AbstractLuxLayer; solver=Tsit5(), tspan=(0.0f0, 1.0f0), kwargs...\n",
    ")\n",
    "    return NeuralODE(model, solver, tspan, kwargs)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "[OrdinaryDiffEq.jl](https://docs.sciml.ai/OrdinaryDiffEq/stable/) can deal with non-Vector\n",
    "Inputs! However, certain discrete sensitivities like `ReverseDiffAdjoint` can't handle\n",
    "non-Vector inputs. Hence, we need to convert the input and output of the ODE solver to a\n",
    "Vector."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function (n::NeuralODE)(x, ps, st)\n",
    "    function dudt(u, p, t)\n",
    "        u_, st = n.model(reshape(u, size(x)), p, st)\n",
    "        return vec(u_)\n",
    "    end\n",
    "    prob = ODEProblem{false}(ODEFunction{false}(dudt), vec(x), n.tspan, ps)\n",
    "    return solve(prob, n.solver; n.kwargs...), st\n",
    "end\n",
    "\n",
    "@views diffeqsol_to_array(l::Int, x::ODESolution) = reshape(last(x.u), (l, :))\n",
    "@views diffeqsol_to_array(l::Int, x::AbstractMatrix) = reshape(x[:, end], (l, :))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create and Initialize the Neural ODE Layer"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function create_model(\n",
    "    model_fn=NeuralODE;\n",
    "    dev=gpu_device(),\n",
    "    use_named_tuple::Bool=false,\n",
    "    sensealg=InterpolatingAdjoint(; autojacvec=ZygoteVJP()),\n",
    ")\n",
    "    # Construct the Neural ODE Model\n",
    "    model = Chain(\n",
    "        FlattenLayer(),\n",
    "        Dense(784 => 20, tanh),\n",
    "        model_fn(\n",
    "            Chain(Dense(20 => 10, tanh), Dense(10 => 10, tanh), Dense(10 => 20, tanh));\n",
    "            save_everystep=false,\n",
    "            reltol=1.0f-3,\n",
    "            abstol=1.0f-3,\n",
    "            save_start=false,\n",
    "            sensealg,\n",
    "        ),\n",
    "        Base.Fix1(diffeqsol_to_array, 20),\n",
    "        Dense(20 => 10),\n",
    "    )\n",
    "\n",
    "    rng = Random.default_rng()\n",
    "    Random.seed!(rng, 0)\n",
    "\n",
    "    ps, st = Lux.setup(rng, model)\n",
    "    if !use_named_tuple\n",
    "        ps = ComponentArray(ps)\n",
    "    end\n",
    "    ps = ps |> dev\n",
    "    st = st |> dev\n",
    "\n",
    "    return model, ps, st\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Utility Functions"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "const logitcrossentropy = CrossEntropyLoss(; logits=Val(true))\n",
    "\n",
    "function accuracy(model, ps, st, dataloader)\n",
    "    total_correct, total = 0, 0\n",
    "    st = Lux.testmode(st)\n",
    "    for (x, y) in dataloader\n",
    "        target_class = onecold(y)\n",
    "        predicted_class = onecold(first(model(x, ps, st)))\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    return total_correct / total\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function train(model_function; cpu::Bool=false, kwargs...)\n",
    "    dev = cpu ? cpu_device() : gpu_device()\n",
    "    model, ps, st = create_model(model_function; dev, kwargs...)\n",
    "\n",
    "    # Training\n",
    "    train_dataloader, test_dataloader = dev(loadmnist(128, 0.9))\n",
    "\n",
    "    tstate = Training.TrainState(model, ps, st, Adam(0.001f0))\n",
    "\n",
    "    ### Lets train the model\n",
    "    nepochs = 9\n",
    "    for epoch in 1:nepochs\n",
    "        stime = time()\n",
    "        for (x, y) in train_dataloader\n",
    "            _, _, _, tstate = Training.single_train_step!(\n",
    "                AutoZygote(), logitcrossentropy, (x, y), tstate\n",
    "            )\n",
    "        end\n",
    "        ttime = time() - stime\n",
    "\n",
    "        tr_acc = accuracy(model, tstate.parameters, tstate.states, train_dataloader) * 100\n",
    "        te_acc = accuracy(model, tstate.parameters, tstate.states, test_dataloader) * 100\n",
    "        @printf \"[%d/%d]\\tTime %.4fs\\tTraining Accuracy: %.5f%%\\tTest \\\n",
    "                 Accuracy: %.5f%%\\n\" epoch nepochs ttime tr_acc te_acc\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "train(NeuralODECompact)\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train(NeuralODE)\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also change the `sensealg` and train the model! `GaussAdjoint` allows you to use\n",
    "any arbitrary parameter structure and not just a flat vector (`ComponentArray`)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train(NeuralODE; sensealg=GaussAdjoint(; autojacvec=ZygoteVJP()), use_named_tuple=true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "But remember some AD backends like `ReverseDiff` is not GPU compatible.\n",
    "For a model this size, you will notice that training time is significantly lower for\n",
    "training on CPU than on GPU."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train(NeuralODE; sensealg=InterpolatingAdjoint(; autojacvec=ReverseDiffVJP()), cpu=true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For completeness, let's also test out discrete sensitivities!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train(NeuralODE; sensealg=ReverseDiffAdjoint(), cpu=true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alternate Implementation using Stateful Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Starting `v0.5.5`, Lux provides a `StatefulLuxLayer` which can be used\n",
    "to avoid the [`Box`ing of `st`](https://github.com/JuliaLang/julia/issues/15276). Using\n",
    "the `@compact` API avoids this problem entirely."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct StatefulNeuralODE{M<:Lux.AbstractLuxLayer,So,T,K} <:\n",
    "       Lux.AbstractLuxWrapperLayer{:model}\n",
    "    model::M\n",
    "    solver::So\n",
    "    tspan::T\n",
    "    kwargs::K\n",
    "end\n",
    "\n",
    "function StatefulNeuralODE(\n",
    "    model::Lux.AbstractLuxLayer; solver=Tsit5(), tspan=(0.0f0, 1.0f0), kwargs...\n",
    ")\n",
    "    return StatefulNeuralODE(model, solver, tspan, kwargs)\n",
    "end\n",
    "\n",
    "function (n::StatefulNeuralODE)(x, ps, st)\n",
    "    st_model = StatefulLuxLayer(n.model, ps, st)\n",
    "    dudt(u, p, t) = st_model(u, p)\n",
    "    prob = ODEProblem{false}(ODEFunction{false}(dudt), x, n.tspan, ps)\n",
    "    return solve(prob, n.solver; n.kwargs...), st_model.st\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the new Stateful Neural ODE"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train(StatefulNeuralODE)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We might not see a significant difference in the training time, but let us investigate\n",
    "the type stabilities of the layers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Type Stability"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model, ps, st = create_model(NeuralODE)\n",
    "\n",
    "model_stateful, ps_stateful, st_stateful = create_model(StatefulNeuralODE)\n",
    "\n",
    "x = ones(Float32, 28, 28, 1, 3) |> gpu_device();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "NeuralODE is not type stable due to the boxing of `st`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@code_warntype model(x, ps, st)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We avoid the problem entirely by using `StatefulNeuralODE`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@code_warntype model_stateful(x, ps_stateful, st_stateful)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note, that we still recommend using this layer internally and not exposing this as the\n",
    "default API to the users."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally checking the compact model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model_compact, ps_compact, st_compact = create_model(NeuralODECompact)\n",
    "\n",
    "@code_warntype model_compact(x, ps_compact, st_compact)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  },
  "kernelspec": {
   "name": "julia-1.12",
   "display_name": "Julia 1.12.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}