import{_ as t,c as e,o as i,a3 as l}from"./chunks/framework.M--zSXWd.js";const k=JSON.parse('{"title":"Boltz","description":"","frontmatter":{},"headers":[],"relativePath":"api/Domain_Specific_Modeling/Boltz.md","filePath":"api/Domain_Specific_Modeling/Boltz.md","lastUpdated":null}'),s={name:"api/Domain_Specific_Modeling/Boltz.md"},a=l(`<h1 id="Boltz" tabindex="-1">Boltz <a class="header-anchor" href="#Boltz" aria-label="Permalink to &quot;Boltz {#Boltz}&quot;">â€‹</a></h1><p>Accelerate âš¡ your ML research using pre-built Deep Learning Models with Lux.</p><h2 id="Index" tabindex="-1">Index <a class="header-anchor" href="#Index" aria-label="Permalink to &quot;Index {#Index}&quot;">â€‹</a></h2><ul><li><a href="#Boltz.ClassTokens"><code>Boltz.ClassTokens</code></a></li><li><a href="#Boltz.MultiHeadAttention"><code>Boltz.MultiHeadAttention</code></a></li><li><a href="#Boltz.ViPosEmbedding"><code>Boltz.ViPosEmbedding</code></a></li><li><a href="#Boltz._fast_chunk"><code>Boltz._fast_chunk</code></a></li><li><a href="#Boltz._flatten_spatial"><code>Boltz._flatten_spatial</code></a></li><li><a href="#Boltz._seconddimmean"><code>Boltz._seconddimmean</code></a></li><li><a href="#Boltz._vgg_block"><code>Boltz._vgg_block</code></a></li><li><a href="#Boltz._vgg_classifier_layers"><code>Boltz._vgg_classifier_layers</code></a></li><li><a href="#Boltz._vgg_convolutional_layers"><code>Boltz._vgg_convolutional_layers</code></a></li><li><a href="#Boltz.transformer_encoder"><code>Boltz.transformer_encoder</code></a></li><li><a href="#Boltz.vgg"><code>Boltz.vgg</code></a></li></ul><h1 id="Computer-Vision-Models" tabindex="-1">Computer Vision Models <a class="header-anchor" href="#Computer-Vision-Models" aria-label="Permalink to &quot;Computer Vision Models {#Computer-Vision-Models}&quot;">â€‹</a></h1><h2 id="Classification-Models:-Native-Lux-Models" tabindex="-1">Classification Models: Native Lux Models <a class="header-anchor" href="#Classification-Models:-Native-Lux-Models" aria-label="Permalink to &quot;Classification Models: Native Lux Models {#Classification-Models:-Native-Lux-Models}&quot;">â€‹</a></h2><table><thead><tr><th style="text-align:right;">MODEL NAME</th><th style="text-align:right;">FUNCTION</th><th style="text-align:right;">NAME</th><th style="text-align:center;">PRETRAINED</th><th style="text-align:center;">TOP 1 ACCURACY (%)</th><th style="text-align:center;">TOP 5 ACCURACY (%)</th></tr></thead><tbody><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg11</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">67.35</td><td style="text-align:center;">87.91</td></tr><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg13</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">68.40</td><td style="text-align:center;">88.48</td></tr><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg16</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">70.24</td><td style="text-align:center;">89.80</td></tr><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg19</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">71.09</td><td style="text-align:center;">90.27</td></tr><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg11_bn</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">69.09</td><td style="text-align:center;">88.94</td></tr><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg13_bn</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">69.66</td><td style="text-align:center;">89.49</td></tr><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg16_bn</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">72.11</td><td style="text-align:center;">91.02</td></tr><tr><td style="text-align:right;">VGG</td><td style="text-align:right;"><code>vgg</code></td><td style="text-align:right;"><code>:vgg19_bn</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">72.95</td><td style="text-align:center;">91.32</td></tr><tr><td style="text-align:right;">Vision Transformer</td><td style="text-align:right;"><code>vision_transformer</code></td><td style="text-align:right;"><code>:tiny</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">Vision Transformer</td><td style="text-align:right;"><code>vision_transformer</code></td><td style="text-align:right;"><code>:small</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">Vision Transformer</td><td style="text-align:right;"><code>vision_transformer</code></td><td style="text-align:right;"><code>:base</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">Vision Transformer</td><td style="text-align:right;"><code>vision_transformer</code></td><td style="text-align:right;"><code>:large</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">Vision Transformer</td><td style="text-align:right;"><code>vision_transformer</code></td><td style="text-align:right;"><code>:huge</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">Vision Transformer</td><td style="text-align:right;"><code>vision_transformer</code></td><td style="text-align:right;"><code>:giant</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">Vision Transformer</td><td style="text-align:right;"><code>vision_transformer</code></td><td style="text-align:right;"><code>:gigantic</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr></tbody></table><h2 id="Building-Blocks" tabindex="-1">Building Blocks <a class="header-anchor" href="#Building-Blocks" aria-label="Permalink to &quot;Building Blocks {#Building-Blocks}&quot;">â€‹</a></h2><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.ClassTokens" href="#Boltz.ClassTokens">#</a>Â <b><u>Boltz.ClassTokens</u></b> â€” <i>Type</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ClassTokens</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(dim; init</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Lux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">zeros32)</span></span></code></pre></div><p>Appends class tokens to an input with embedding dimension <code>dim</code> for use in many vision transformer namels.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vit.jl#L59-L64" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.MultiHeadAttention" href="#Boltz.MultiHeadAttention">#</a>Â <b><u>Boltz.MultiHeadAttention</u></b> â€” <i>Type</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MultiHeadAttention</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(in_planes</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, number_heads</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; qkv_bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                   attention_dropout_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">T</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0f0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                   projection_dropout_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">T</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0f0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">where</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {T}</span></span></code></pre></div><p>Multi-head self-attention layer</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vit.jl#L2-L8" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.ViPosEmbedding" href="#Boltz.ViPosEmbedding">#</a>Â <b><u>Boltz.ViPosEmbedding</u></b> â€” <i>Type</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ViPosEmbedding</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(embedsize, npatches;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">               init </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (rng, dims</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> randn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(rng, Float32, dims</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><p>Positional embedding layer used by many vision transformer-like namels.</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vit.jl#L83-L88" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.transformer_encoder" href="#Boltz.transformer_encoder">#</a>Â <b><u>Boltz.transformer_encoder</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">transformer_encoder</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(in_planes, depth, number_heads; mlp_ratio </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 4.0f0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, dropout </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.0f0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Transformer as used in the base ViT architecture. (<a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noreferrer">reference</a>).</p><p><strong>Arguments</strong></p><ul><li><p><code>in_planes</code>: number of input channels</p></li><li><p><code>depth</code>: number of attention blocks</p></li><li><p><code>number_heads</code>: number of attention heads</p></li><li><p><code>mlp_ratio</code>: ratio of MLP layers to the number of input channels</p></li><li><p><code>dropout_rate</code>: dropout rate</p></li></ul><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vit.jl#L106-L119" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz.vgg" href="#Boltz.vgg">#</a>Â <b><u>Boltz.vgg</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">vgg</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(imsize; config, inchannels, batchnorm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, nclasses, fcsize, dropout)</span></span></code></pre></div><p>Create a VGG model (<a href="https://arxiv.org/abs/1409.1556v6" target="_blank" rel="noreferrer">reference</a>).</p><p><strong>Arguments</strong></p><ul><li><p><code>imsize</code>: input image width and height as a tuple</p></li><li><p><code>config</code>: the configuration for the convolution layers</p></li><li><p><code>inchannels</code>: number of input channels</p></li><li><p><code>batchnorm</code>: set to <code>true</code> to use batch normalization after each convolution</p></li><li><p><code>nclasses</code>: number of output classes</p></li><li><p><code>fcsize</code>: intermediate fully connected layer size (see <code>Metalhead._vgg_classifier_layers</code>)</p></li><li><p><code>dropout</code>: dropout level between fully connected layers</p></li></ul><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vgg.jl#L67-L82" target="_blank" rel="noreferrer">source</a></p></div><br><h3 id="Non-Public-API" tabindex="-1">Non-Public API <a class="header-anchor" href="#Non-Public-API" aria-label="Permalink to &quot;Non-Public API {#Non-Public-API}&quot;">â€‹</a></h3><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz._seconddimmean" href="#Boltz._seconddimmean">#</a>Â <b><u>Boltz._seconddimmean</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">_seconddimmean</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x)</span></span></code></pre></div><p>Computes the mean of <code>x</code> along dimension <code>2</code></p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/utils.jl#L27-L31" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz._fast_chunk" href="#Boltz._fast_chunk">#</a>Â <b><u>Boltz._fast_chunk</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">_fast_chunk</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Val{n}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Val{dim}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Type-stable and faster version of <code>MLUtils.chunk</code></p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/utils.jl#L1-L5" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz._flatten_spatial" href="#Boltz._flatten_spatial">#</a>Â <b><u>Boltz._flatten_spatial</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">_flatten_spatial</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray{T, 4}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Flattens the first 2 dimensions of <code>x</code>, and permutes the remaining dimensions to (2, 1, 3)</p><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/utils.jl#L18-L22" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz._vgg_block" href="#Boltz._vgg_block">#</a>Â <b><u>Boltz._vgg_block</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">_vgg_block</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(input_filters, output_filters, depth, batchnorm)</span></span></code></pre></div><p>A VGG block of convolution layers (<a href="https://arxiv.org/abs/1409.1556v6" target="_blank" rel="noreferrer">reference</a>).</p><p><strong>Arguments</strong></p><ul><li><p><code>input_filters</code>: number of input feature maps</p></li><li><p><code>output_filters</code>: number of output feature maps</p></li><li><p><code>depth</code>: number of convolution/convolution + batch norm layers</p></li><li><p><code>batchnorm</code>: set to <code>true</code> to include batch normalization after each convolution</p></li></ul><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vgg.jl#L1-L12" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz._vgg_classifier_layers" href="#Boltz._vgg_classifier_layers">#</a>Â <b><u>Boltz._vgg_classifier_layers</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">_vgg_classifier_layers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(imsize, nclasses, fcsize, dropout)</span></span></code></pre></div><p>Create VGG classifier (fully connected) layers (<a href="https://arxiv.org/abs/1409.1556v6" target="_blank" rel="noreferrer">reference</a>).</p><p><strong>Arguments</strong></p><ul><li><p><code>imsize</code>: tuple <code>(width, height, channels)</code> indicating the size after the convolution layers (see <code>Metalhead._vgg_convolutional_layers</code>)</p></li><li><p><code>nclasses</code>: number of output classes</p></li><li><p><code>fcsize</code>: input and output size of the intermediate fully connected layer</p></li><li><p><code>dropout</code>: the dropout level between each fully connected layer</p></li></ul><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vgg.jl#L48-L61" target="_blank" rel="noreferrer">source</a></p></div><br><div style="border-width:1px;border-style:solid;border-color:black;padding:1em;border-radius:25px;"><a id="Boltz._vgg_convolutional_layers" href="#Boltz._vgg_convolutional_layers">#</a>Â <b><u>Boltz._vgg_convolutional_layers</u></b> â€” <i>Function</i>. <div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">_vgg_convolutional_layers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(config, batchnorm, inchannels)</span></span></code></pre></div><p>Create VGG convolution layers (<a href="https://arxiv.org/abs/1409.1556v6" target="_blank" rel="noreferrer">reference</a>).</p><p><strong>Arguments</strong></p><ul><li><p><code>config</code>: vector of tuples <code>(output_channels, num_convolutions)</code> for each block (see <code>Metalhead._vgg_block</code>)</p></li><li><p><code>batchnorm</code>: set to <code>true</code> to include batch normalization after each convolution</p></li><li><p><code>inchannels</code>: number of input channels</p></li></ul><p><a href="https://github.com/LuxDL/Boltz.jl/blob/v0.3.3/src/vision/vgg.jl#L25-L36" target="_blank" rel="noreferrer">source</a></p></div><br><h2 id="Classification-Models:-Imported-from-Metalhead.jl" tabindex="-1">Classification Models: Imported from Metalhead.jl <a class="header-anchor" href="#Classification-Models:-Imported-from-Metalhead.jl" aria-label="Permalink to &quot;Classification Models: Imported from Metalhead.jl {#Classification-Models:-Imported-from-Metalhead.jl}&quot;">â€‹</a></h2><div class="tip custom-block"><p class="custom-block-title">Tip</p><p>You need to load <code>Flux</code> and <code>Metalhead</code> before using these models.</p></div><table><thead><tr><th style="text-align:right;">MODEL NAME</th><th style="text-align:right;">FUNCTION</th><th style="text-align:right;">NAME</th><th style="text-align:center;">PRETRAINED</th><th style="text-align:center;">TOP 1 ACCURACY (%)</th><th style="text-align:center;">TOP 5 ACCURACY (%)</th></tr></thead><tbody><tr><td style="text-align:right;">AlexNet</td><td style="text-align:right;"><code>alexnet</code></td><td style="text-align:right;"><code>:alexnet</code></td><td style="text-align:center;">âœ…</td><td style="text-align:center;">54.48</td><td style="text-align:center;">77.72</td></tr><tr><td style="text-align:right;">ResNet</td><td style="text-align:right;"><code>resnet</code></td><td style="text-align:right;"><code>:resnet18</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;">68.08</td><td style="text-align:center;">88.44</td></tr><tr><td style="text-align:right;">ResNet</td><td style="text-align:right;"><code>resnet</code></td><td style="text-align:right;"><code>:resnet34</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;">72.13</td><td style="text-align:center;">90.91</td></tr><tr><td style="text-align:right;">ResNet</td><td style="text-align:right;"><code>resnet</code></td><td style="text-align:right;"><code>:resnet50</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;">74.55</td><td style="text-align:center;">92.36</td></tr><tr><td style="text-align:right;">ResNet</td><td style="text-align:right;"><code>resnet</code></td><td style="text-align:right;"><code>:resnet101</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;">74.81</td><td style="text-align:center;">92.36</td></tr><tr><td style="text-align:right;">ResNet</td><td style="text-align:right;"><code>resnet</code></td><td style="text-align:right;"><code>:resnet152</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;">77.63</td><td style="text-align:center;">93.84</td></tr><tr><td style="text-align:right;">ConvMixer</td><td style="text-align:right;"><code>convmixer</code></td><td style="text-align:right;"><code>:small</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">ConvMixer</td><td style="text-align:right;"><code>convmixer</code></td><td style="text-align:right;"><code>:base</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">ConvMixer</td><td style="text-align:right;"><code>convmixer</code></td><td style="text-align:right;"><code>:large</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">DenseNet</td><td style="text-align:right;"><code>densenet</code></td><td style="text-align:right;"><code>:densenet121</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">DenseNet</td><td style="text-align:right;"><code>densenet</code></td><td style="text-align:right;"><code>:densenet161</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">DenseNet</td><td style="text-align:right;"><code>densenet</code></td><td style="text-align:right;"><code>:densenet169</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">DenseNet</td><td style="text-align:right;"><code>densenet</code></td><td style="text-align:right;"><code>:densenet201</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">GoogleNet</td><td style="text-align:right;"><code>googlenet</code></td><td style="text-align:right;"><code>:googlenet</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">MobileNet</td><td style="text-align:right;"><code>mobilenet</code></td><td style="text-align:right;"><code>:mobilenet_v1</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">MobileNet</td><td style="text-align:right;"><code>mobilenet</code></td><td style="text-align:right;"><code>:mobilenet_v2</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">MobileNet</td><td style="text-align:right;"><code>mobilenet</code></td><td style="text-align:right;"><code>:mobilenet_v3_small</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">MobileNet</td><td style="text-align:right;"><code>mobilenet</code></td><td style="text-align:right;"><code>:mobilenet_v3_large</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">ResNeXT</td><td style="text-align:right;"><code>resnext</code></td><td style="text-align:right;"><code>:resnext50</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">ResNeXT</td><td style="text-align:right;"><code>resnext</code></td><td style="text-align:right;"><code>:resnext101</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:right;">ResNeXT</td><td style="text-align:right;"><code>resnext</code></td><td style="text-align:right;"><code>:resnext152</code></td><td style="text-align:center;">ðŸš«</td><td style="text-align:center;"></td><td style="text-align:center;"></td></tr></tbody></table><p>These models can be created using <code>&lt;FUNCTION&gt;(&lt;NAME&gt;; pretrained = &lt;PRETRAINED&gt;)</code></p><h3 id="Preprocessing" tabindex="-1">Preprocessing <a class="header-anchor" href="#Preprocessing" aria-label="Permalink to &quot;Preprocessing {#Preprocessing}&quot;">â€‹</a></h3><p>All the pretrained models require that the images be normalized with the parameters <code>mean = [0.485f0, 0.456f0, 0.406f0]</code> and <code>std = [0.229f0, 0.224f0, 0.225f0]</code>.</p>`,37),d=[a];function n(r,o,c,g,h,p){return i(),e("div",null,d)}const u=t(s,[["render",n]]);export{k as __pageData,u as default};
