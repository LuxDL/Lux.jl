{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training a HyperNetwork on MNIST and FashionMNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Package Imports"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Lux,\n",
    "    ComponentArrays, MLDatasets, MLUtils, OneHotArrays, Optimisers, Printf, Random, Reactant"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Datasets"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function load_dataset(\n",
    "    ::Type{dset}, n_train::Union{Nothing,Int}, n_eval::Union{Nothing,Int}, batchsize::Int\n",
    ") where {dset}\n",
    "    (; features, targets) = if n_train === nothing\n",
    "        tmp = dset(:train)\n",
    "        tmp[1:length(tmp)]\n",
    "    else\n",
    "        dset(:train)[1:n_train]\n",
    "    end\n",
    "    x_train, y_train = reshape(features, 28, 28, 1, :), onehotbatch(targets, 0:9)\n",
    "\n",
    "    (; features, targets) = if n_eval === nothing\n",
    "        tmp = dset(:test)\n",
    "        tmp[1:length(tmp)]\n",
    "    else\n",
    "        dset(:test)[1:n_eval]\n",
    "    end\n",
    "    x_test, y_test = reshape(features, 28, 28, 1, :), onehotbatch(targets, 0:9)\n",
    "\n",
    "    return (\n",
    "        DataLoader(\n",
    "            (x_train, y_train);\n",
    "            batchsize=min(batchsize, size(x_train, 4)),\n",
    "            shuffle=true,\n",
    "            partial=false,\n",
    "        ),\n",
    "        DataLoader(\n",
    "            (x_test, y_test);\n",
    "            batchsize=min(batchsize, size(x_test, 4)),\n",
    "            shuffle=false,\n",
    "            partial=false,\n",
    "        ),\n",
    "    )\n",
    "end\n",
    "\n",
    "function load_datasets(batchsize=32)\n",
    "    n_train = parse(Bool, get(ENV, \"CI\", \"false\")) ? 1024 : nothing\n",
    "    n_eval = parse(Bool, get(ENV, \"CI\", \"false\")) ? 32 : nothing\n",
    "    return load_dataset.((MNIST, FashionMNIST), n_train, n_eval, batchsize)\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement a HyperNet Layer"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function HyperNet(weight_generator::AbstractLuxLayer, core_network::AbstractLuxLayer)\n",
    "    ca_axes = getaxes(\n",
    "        ComponentArray(Lux.initialparameters(Random.default_rng(), core_network))\n",
    "    )\n",
    "    return @compact(; ca_axes, weight_generator, core_network, dispatch=:HyperNet) do (x, y)\n",
    "        # Generate the weights\n",
    "        ps_new = ComponentArray(vec(weight_generator(x)), ca_axes)\n",
    "        @return core_network(y, ps_new)\n",
    "    end\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining functions on the CompactLuxLayer requires some understanding of how the layer\n",
    "is structured, as such we don't recommend doing it unless you are familiar with the\n",
    "internals. In this case, we simply write it to ignore the initialization of the\n",
    "`core_network` parameters."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function Lux.initialparameters(rng::AbstractRNG, hn::CompactLuxLayer{:HyperNet})\n",
    "    return (; weight_generator=Lux.initialparameters(rng, hn.layers.weight_generator))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create and Initialize the HyperNet"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function create_model()\n",
    "    core_network = Chain(\n",
    "        Conv((3, 3), 1 => 16, relu; stride=2),\n",
    "        Conv((3, 3), 16 => 32, relu; stride=2),\n",
    "        Conv((3, 3), 32 => 64, relu; stride=2),\n",
    "        GlobalMeanPool(),\n",
    "        FlattenLayer(),\n",
    "        Dense(64, 10),\n",
    "    )\n",
    "    return HyperNet(\n",
    "        Chain(\n",
    "            Embedding(2 => 32),\n",
    "            Dense(32, 64, relu),\n",
    "            Dense(64, Lux.parameterlength(core_network)),\n",
    "        ),\n",
    "        core_network,\n",
    "    )\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Utility Functions"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function accuracy(model, ps, st, dataloader, data_idx)\n",
    "    total_correct, total = 0, 0\n",
    "    cdev = cpu_device()\n",
    "    st = Lux.testmode(st)\n",
    "    for (x, y) in dataloader\n",
    "        ŷ, _ = model((data_idx, x), ps, st)\n",
    "        target_class = y |> cdev |> onecold\n",
    "        predicted_class = ŷ |> cdev |> onecold\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    return total_correct / total\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function train()\n",
    "    dev = reactant_device(; force=true)\n",
    "\n",
    "    model = create_model()\n",
    "    dataloaders = load_datasets() |> dev\n",
    "\n",
    "    Random.seed!(1234)\n",
    "    ps, st = Lux.setup(Random.default_rng(), model) |> dev\n",
    "\n",
    "    train_state = Training.TrainState(model, ps, st, Adam(0.0003f0))\n",
    "\n",
    "    x = first(first(dataloaders[1][1]))\n",
    "    data_idx = ConcreteRNumber(1)\n",
    "    model_compiled = @compile model((data_idx, x), ps, Lux.testmode(st))\n",
    "\n",
    "    ### Let's train the model\n",
    "    nepochs = 50\n",
    "    for epoch in 1:nepochs, data_idx in 1:2\n",
    "        train_dataloader, test_dataloader = dev.(dataloaders[data_idx])\n",
    "\n",
    "        ### This allows us to trace the data index, else it will be embedded as a constant\n",
    "        ### in the IR\n",
    "        concrete_data_idx = ConcreteRNumber(data_idx)\n",
    "\n",
    "        stime = time()\n",
    "        for (x, y) in train_dataloader\n",
    "            (_, _, _, train_state) = Training.single_train_step!(\n",
    "                AutoEnzyme(),\n",
    "                CrossEntropyLoss(; logits=Val(true)),\n",
    "                ((concrete_data_idx, x), y),\n",
    "                train_state;\n",
    "                return_gradients=Val(false),\n",
    "            )\n",
    "        end\n",
    "        ttime = time() - stime\n",
    "\n",
    "        train_acc = round(\n",
    "            accuracy(\n",
    "                model_compiled,\n",
    "                train_state.parameters,\n",
    "                train_state.states,\n",
    "                train_dataloader,\n",
    "                concrete_data_idx,\n",
    "            ) * 100;\n",
    "            digits=2,\n",
    "        )\n",
    "        test_acc = round(\n",
    "            accuracy(\n",
    "                model_compiled,\n",
    "                train_state.parameters,\n",
    "                train_state.states,\n",
    "                test_dataloader,\n",
    "                concrete_data_idx,\n",
    "            ) * 100;\n",
    "            digits=2,\n",
    "        )\n",
    "\n",
    "        data_name = data_idx == 1 ? \"MNIST\" : \"FashionMNIST\"\n",
    "\n",
    "        @printf \"[%3d/%3d]\\t%12s\\tTime %3.5fs\\tTraining Accuracy: %3.2f%%\\tTest \\\n",
    "                 Accuracy: %3.2f%%\\n\" epoch nepochs data_name ttime train_acc test_acc\n",
    "    end\n",
    "\n",
    "    println()\n",
    "\n",
    "    test_acc_list = [0.0, 0.0]\n",
    "    for data_idx in 1:2\n",
    "        train_dataloader, test_dataloader = dev.(dataloaders[data_idx])\n",
    "\n",
    "        concrete_data_idx = ConcreteRNumber(data_idx)\n",
    "        train_acc = round(\n",
    "            accuracy(\n",
    "                model_compiled,\n",
    "                train_state.parameters,\n",
    "                train_state.states,\n",
    "                train_dataloader,\n",
    "                concrete_data_idx,\n",
    "            ) * 100;\n",
    "            digits=2,\n",
    "        )\n",
    "        test_acc = round(\n",
    "            accuracy(\n",
    "                model_compiled,\n",
    "                train_state.parameters,\n",
    "                train_state.states,\n",
    "                test_dataloader,\n",
    "                concrete_data_idx,\n",
    "            ) * 100;\n",
    "            digits=2,\n",
    "        )\n",
    "\n",
    "        data_name = data_idx == 1 ? \"MNIST\" : \"FashionMNIST\"\n",
    "\n",
    "        @printf \"[FINAL]\\t%12s\\tTraining Accuracy: %3.2f%%\\tTest Accuracy: \\\n",
    "                 %3.2f%%\\n\" data_name train_acc test_acc\n",
    "        test_acc_list[data_idx] = test_acc\n",
    "    end\n",
    "    return test_acc_list\n",
    "end\n",
    "\n",
    "test_acc_list = train()\n",
    "@assert test_acc_list[1] > 35 && test_acc_list[2] > 35 #hide\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.8"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.8",
   "language": "julia"
  }
 },
 "nbformat": 4
}