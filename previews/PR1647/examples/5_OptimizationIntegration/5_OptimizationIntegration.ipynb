{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fitting with Optimization.jl"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lux's native Training.TrainState is a great API for gradient-based learning of\n",
    "neural networks, however, it is geared towards using `Optimisers.jl` as the backend.\n",
    "However, often times we want to train the neural networks with other optimization methods\n",
    "like BFGS, LBFGS, etc. In this tutorial, we will show how to train Lux models with\n",
    "Optimization.jl that provides a simple unified interface to various optimization methods."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will base our tutorial on the minibatching tutorial from the official\n",
    "[Optimization.jl](https://docs.sciml.ai/Optimization/stable/tutorials/minibatch/) docs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "!!! note \"Neural ODE\"\n",
    "\n",
    "    This tutorial uses a Neural ODE, however, we won't discuss that part in this tutorial.\n",
    "    Please refer to the Neural ODE tutorial for more information."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports packages"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Lux,\n",
    "    Optimization,\n",
    "    OptimizationOptimisers,\n",
    "    OptimizationOptimJL,\n",
    "    OrdinaryDiffEqTsit5,\n",
    "    SciMLSensitivity,\n",
    "    Random,\n",
    "    MLUtils,\n",
    "    CairoMakie,\n",
    "    ComponentArrays,\n",
    "    Printf\n",
    "\n",
    "const gdev = gpu_device()\n",
    "const cdev = cpu_device()\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate some training data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function lotka_volterra(du, u, p, t)\n",
    "    x, y = u\n",
    "    α, β, δ, γ = p\n",
    "    du[1] = α * x - β * x * y\n",
    "    du[2] = -δ * y + γ * x * y\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "u0 = [1.0f0, 1.0f0]\n",
    "\n",
    "datasize = 32\n",
    "tspan = (0.0f0, 2.0f0)\n",
    "\n",
    "const t = range(tspan[1], tspan[2]; length=datasize)\n",
    "true_prob = ODEProblem(lotka_volterra, u0, (tspan[1], tspan[2]), [1.5, 1.0, 3.0, 1.0])\n",
    "const ode_data = Array(solve(true_prob, Tsit5(); saveat=t))\n",
    "\n",
    "begin\n",
    "    fig = Figure()\n",
    "    ax = CairoMakie.Axis(fig[1, 1])\n",
    "    lines!(ax, t, ode_data[1, :]; label=L\"u_1(t)\", color=:blue, linestyle=:dot, linewidth=4)\n",
    "    lines!(ax, t, ode_data[2, :]; label=L\"u_2(t)\", color=:red, linestyle=:dot, linewidth=4)\n",
    "    axislegend(ax; position=:lt)\n",
    "    fig\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will define the DataLoader to batch over the data, additionally we will pipe it through\n",
    "the `gdev` device to move the data to the GPU on each iteration."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default `gdev` will move all objects to the GPU. But we don't want to move the time\n",
    "vector to the GPU. So we will wrap it in a struct and mark it as a leaf using\n",
    "MLDataDevices.isleaf"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct TimeWrapper{T}\n",
    "    t::T\n",
    "end\n",
    "\n",
    "MLDataDevices.isleaf(::TimeWrapper) = true\n",
    "\n",
    "Base.length(t::TimeWrapper) = length(t.t)\n",
    "\n",
    "Base.getindex(t::TimeWrapper, i) = TimeWrapper(t.t[i])\n",
    "\n",
    "dataloader = DataLoader((ode_data, TimeWrapper(t)); batchsize=8) |> gdev\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are using different optimization methods for demonstration purposes. This problem\n",
    "is trivial enough to not require this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimization.jl requires an abstract array as the parameters, hence we will construct a\n",
    "`ComponentArray` to store the parameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "!!! note \"Parameter Estimation vs State Estimation\"\n",
    "\n",
    "    Optimization.jl performs state estimation, which effectively means for a function\n",
    "    `f(u, p)`, it is trying to compute the optimal `u` for a given `p`. This terminology\n",
    "    might be confusing to ML practitioners, since in the ML world, we usually do parameter\n",
    "    estimation. This effectively means that the `u` in Optimization.jl corresponds to our\n",
    "    model parameters that is being optimized."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function train_model(dataloader)\n",
    "    model = Chain(Dense(2, 32, tanh), Dense(32, 32, tanh), Dense(32, 2))\n",
    "    ps, st = Lux.setup(Random.default_rng(), model)\n",
    "\n",
    "    ps_ca = ComponentArray(ps) |> gdev\n",
    "    st = st |> gdev\n",
    "\n",
    "    function callback(state, l)\n",
    "        if state.iter == 1 || state.iter % 25 == 0\n",
    "            @printf \"Iteration: %5d, Loss: %.6e\\n\" state.iter l\n",
    "        end\n",
    "        return l < 1.0e-8 ## Terminate if loss is small\n",
    "    end\n",
    "\n",
    "    smodel = StatefulLuxLayer(model, nothing, st)\n",
    "\n",
    "    function loss_adjoint(θ, (u_batch, t_batch))\n",
    "        t_batch = t_batch.t\n",
    "        u0 = u_batch[:, 1]\n",
    "        dudt(u, p, t) = smodel(u, p)\n",
    "        prob = ODEProblem(dudt, u0, (t_batch[1], t_batch[end]), θ)\n",
    "        sol = solve(prob, Tsit5(); sensealg=InterpolatingAdjoint(), saveat=t_batch)\n",
    "        pred = stack(sol.u)\n",
    "        return MSELoss()(pred, u_batch)\n",
    "    end\n",
    "\n",
    "    # Define the Optimization Function that takes in the optimization state (our parameters)\n",
    "    # and optimization parameters (nothing in our case) and data from the dataloader and\n",
    "    # returns the loss.\n",
    "    opt_func = OptimizationFunction(loss_adjoint, Optimization.AutoZygote())\n",
    "    opt_prob = OptimizationProblem(opt_func, ps_ca, dataloader)\n",
    "\n",
    "    epochs = 25\n",
    "    res_adam = solve(opt_prob, Optimisers.Adam(0.001); callback, epochs)\n",
    "\n",
    "    # Let's finetune a bit with L-BFGS\n",
    "    opt_prob = OptimizationProblem(opt_func, res_adam.u, (gdev(ode_data), TimeWrapper(t)))\n",
    "    res_lbfgs = solve(opt_prob, LBFGS(); callback, maxiters=epochs)\n",
    "\n",
    "    # Now that we have a good fit, let's train it on the entire dataset without\n",
    "    # Minibatching. We need to do this since ODE solves can lead to accumulated errors if\n",
    "    # the model was trained on individual parts (without a data-shooting approach).\n",
    "    opt_prob = remake(opt_prob; u0=res_lbfgs.u)\n",
    "    res = solve(opt_prob, Optimisers.Adam(0.005); maxiters=500, callback)\n",
    "\n",
    "    return StatefulLuxLayer(model, res.u, smodel.st)\n",
    "end\n",
    "\n",
    "trained_model = train_model(dataloader)\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the results"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dudt(u, p, t) = trained_model(u, p)\n",
    "prob = ODEProblem(dudt, gdev(u0), (tspan[1], tspan[2]), trained_model.ps)\n",
    "sol = solve(prob, Tsit5(); saveat=t)\n",
    "pred = convert(AbstractArray, sol) |> cdev\n",
    "\n",
    "begin\n",
    "    fig = Figure()\n",
    "    ax = CairoMakie.Axis(fig[1, 1])\n",
    "    lines!(ax, t, ode_data[1, :]; label=L\"u_1(t)\", color=:blue, linestyle=:dot, linewidth=4)\n",
    "    lines!(ax, t, ode_data[2, :]; label=L\"u_2(t)\", color=:red, linestyle=:dot, linewidth=4)\n",
    "    lines!(ax, t, pred[1, :]; label=L\"\\hat{u}_1(t)\", color=:blue, linewidth=4)\n",
    "    lines!(ax, t, pred[2, :]; label=L\"\\hat{u}_2(t)\", color=:red, linewidth=4)\n",
    "    axislegend(ax; position=:lt)\n",
    "    fig\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  },
  "kernelspec": {
   "name": "julia-1.12",
   "display_name": "Julia 1.12.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}