{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional VAE for MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convolutional variational autoencoder (CVAE) implementation in MLX using MNIST. This is\n",
    "based on the [CVAE implementation in MLX](https://github.com/ml-explore/mlx-examples/blob/main/cvae/)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Lux,\n",
    "    Reactant,\n",
    "    MLDatasets,\n",
    "    Random,\n",
    "    Statistics,\n",
    "    Enzyme,\n",
    "    MLUtils,\n",
    "    DataAugmentation,\n",
    "    ConcreteStructs,\n",
    "    OneHotArrays,\n",
    "    ImageShow,\n",
    "    Images,\n",
    "    Printf,\n",
    "    Optimisers\n",
    "\n",
    "const xdev = reactant_device(; force=true)\n",
    "const cdev = cpu_device()\n",
    "\n",
    "const IN_VSCODE = isdefined(Main, :VSCodeServer)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we will define the encoder.It maps the input to a normal distribution in latent\n",
    "space and sample a latent vector from that distribution."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function cvae_encoder(\n",
    "    rng=Random.default_rng();\n",
    "    num_latent_dims::Int,\n",
    "    image_shape::Dims{3},\n",
    "    max_num_filters::Int,\n",
    ")\n",
    "    flattened_dim = prod(image_shape[1:2] .÷ 8) * max_num_filters\n",
    "    return @compact(;\n",
    "        embed=Chain(\n",
    "            Chain(\n",
    "                Conv((3, 3), image_shape[3] => max_num_filters ÷ 4; stride=2, pad=1),\n",
    "                BatchNorm(max_num_filters ÷ 4, leakyrelu),\n",
    "            ),\n",
    "            Chain(\n",
    "                Conv((3, 3), max_num_filters ÷ 4 => max_num_filters ÷ 2; stride=2, pad=1),\n",
    "                BatchNorm(max_num_filters ÷ 2, leakyrelu),\n",
    "            ),\n",
    "            Chain(\n",
    "                Conv((3, 3), max_num_filters ÷ 2 => max_num_filters; stride=2, pad=1),\n",
    "                BatchNorm(max_num_filters, leakyrelu),\n",
    "            ),\n",
    "            FlattenLayer(),\n",
    "        ),\n",
    "        proj_mu=Dense(flattened_dim, num_latent_dims; init_bias=zeros32),\n",
    "        proj_log_var=Dense(flattened_dim, num_latent_dims; init_bias=zeros32),\n",
    "        rng\n",
    "    ) do x\n",
    "        y = embed(x)\n",
    "\n",
    "        μ = proj_mu(y)\n",
    "        logσ² = proj_log_var(y)\n",
    "\n",
    "        T = eltype(logσ²)\n",
    "        logσ² = clamp.(logσ², -T(20.0f0), T(10.0f0))\n",
    "        σ = exp.(logσ² .* T(0.5))\n",
    "\n",
    "        # Generate a tensor of random values from a normal distribution\n",
    "        ϵ = randn_like(Lux.replicate(rng), σ)\n",
    "\n",
    "        # Reparameterization trick to backpropagate through sampling\n",
    "        z = ϵ .* σ .+ μ\n",
    "\n",
    "        @return z, μ, logσ²\n",
    "    end\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similarly we define the decoder."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function cvae_decoder(; num_latent_dims::Int, image_shape::Dims{3}, max_num_filters::Int)\n",
    "    flattened_dim = prod(image_shape[1:2] .÷ 8) * max_num_filters\n",
    "    return @compact(;\n",
    "        linear=Dense(num_latent_dims, flattened_dim),\n",
    "        upchain=Chain(\n",
    "            Chain(\n",
    "                Upsample(2),\n",
    "                Conv((3, 3), max_num_filters => max_num_filters ÷ 2; stride=1, pad=1),\n",
    "                BatchNorm(max_num_filters ÷ 2, leakyrelu),\n",
    "            ),\n",
    "            Chain(\n",
    "                Upsample(2),\n",
    "                Conv((3, 3), max_num_filters ÷ 2 => max_num_filters ÷ 4; stride=1, pad=1),\n",
    "                BatchNorm(max_num_filters ÷ 4, leakyrelu),\n",
    "            ),\n",
    "            Chain(\n",
    "                Upsample(2),\n",
    "                Conv(\n",
    "                    (3, 3), max_num_filters ÷ 4 => image_shape[3], sigmoid; stride=1, pad=1\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        max_num_filters\n",
    "    ) do x\n",
    "        y = linear(x)\n",
    "        img = reshape(y, image_shape[1] ÷ 8, image_shape[2] ÷ 8, max_num_filters, :)\n",
    "        @return upchain(img)\n",
    "    end\n",
    "end\n",
    "\n",
    "@concrete struct CVAE <: AbstractLuxContainerLayer{(:encoder, :decoder)}\n",
    "    encoder <: AbstractLuxLayer\n",
    "    decoder <: AbstractLuxLayer\n",
    "end\n",
    "\n",
    "function CVAE(\n",
    "    rng=Random.default_rng();\n",
    "    num_latent_dims::Int,\n",
    "    image_shape::Dims{3},\n",
    "    max_num_filters::Int,\n",
    ")\n",
    "    decoder = cvae_decoder(; num_latent_dims, image_shape, max_num_filters)\n",
    "    encoder = cvae_encoder(rng; num_latent_dims, image_shape, max_num_filters)\n",
    "    return CVAE(encoder, decoder)\n",
    "end\n",
    "\n",
    "function (cvae::CVAE)(x, ps, st)\n",
    "    (z, μ, logσ²), st_enc = cvae.encoder(x, ps.encoder, st.encoder)\n",
    "    x_rec, st_dec = cvae.decoder(z, ps.decoder, st.decoder)\n",
    "    return (x_rec, μ, logσ²), (; encoder=st_enc, decoder=st_dec)\n",
    "end\n",
    "\n",
    "function encode(cvae::CVAE, x, ps, st)\n",
    "    (z, _, _), st_enc = cvae.encoder(x, ps.encoder, st.encoder)\n",
    "    return z, (; encoder=st_enc, st.decoder)\n",
    "end\n",
    "\n",
    "function decode(cvae::CVAE, z, ps, st)\n",
    "    x_rec, st_dec = cvae.decoder(z, ps.decoder, st.decoder)\n",
    "    return x_rec, (; decoder=st_dec, st.encoder)\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading MNIST"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@concrete struct TensorDataset\n",
    "    dataset\n",
    "    transform\n",
    "    total_samples::Int\n",
    "end\n",
    "\n",
    "Base.length(ds::TensorDataset) = ds.total_samples\n",
    "\n",
    "function Base.getindex(ds::TensorDataset, idxs::Union{Vector{<:Integer},AbstractRange})\n",
    "    img = Image.(eachslice(convert2image(ds.dataset, idxs); dims=3))\n",
    "    return stack(parent ∘ itemdata ∘ Base.Fix1(apply, ds.transform), img)\n",
    "end\n",
    "\n",
    "function loadmnist(batchsize, image_size::Dims{2})\n",
    "    # Load MNIST: Only 1500 for demonstration purposes on CI\n",
    "    train_dataset = MNIST(; split=:train)\n",
    "    N = parse(Bool, get(ENV, \"CI\", \"false\")) ? 5000 : length(train_dataset)\n",
    "\n",
    "    train_transform = ScaleKeepAspect(image_size) |> ImageToTensor()\n",
    "    trainset = TensorDataset(train_dataset, train_transform, N)\n",
    "    trainloader = DataLoader(trainset; batchsize, shuffle=true, partial=false)\n",
    "\n",
    "    return trainloader\n",
    "end\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate an Image Grid from a list of images"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function create_image_grid(imgs::AbstractArray, grid_rows::Int, grid_cols::Int)\n",
    "    total_images = grid_rows * grid_cols\n",
    "    imgs = map(eachslice(imgs[:, :, :, 1:total_images]; dims=4)) do img\n",
    "        cimg = if size(img, 3) == 1\n",
    "            colorview(Gray, view(img, :, :, 1))\n",
    "        else\n",
    "            colorview(RGB, permutedims(img, (3, 1, 2)))\n",
    "        end\n",
    "        return cimg'\n",
    "    end\n",
    "    return create_image_grid(imgs, grid_rows, grid_cols)\n",
    "end\n",
    "\n",
    "function create_image_grid(images::Vector, grid_rows::Int, grid_cols::Int)\n",
    "    # Check if the number of images matches the grid\n",
    "    total_images = grid_rows * grid_cols\n",
    "    @assert length(images) == total_images\n",
    "\n",
    "    # Get the size of a single image (assuming all images are the same size)\n",
    "    img_height, img_width = size(images[1])\n",
    "\n",
    "    # Create a blank grid canvas\n",
    "    grid_height = img_height * grid_rows\n",
    "    grid_width = img_width * grid_cols\n",
    "    grid_canvas = similar(images[1], grid_height, grid_width)\n",
    "\n",
    "    # Place each image in the correct position on the canvas\n",
    "    for idx in 1:total_images\n",
    "        row = div(idx - 1, grid_cols) + 1\n",
    "        col = mod(idx - 1, grid_cols) + 1\n",
    "\n",
    "        start_row = (row - 1) * img_height + 1\n",
    "        start_col = (col - 1) * img_width + 1\n",
    "\n",
    "        grid_canvas[start_row:(start_row + img_height - 1), start_col:(start_col + img_width - 1)] .= images[idx]\n",
    "    end\n",
    "\n",
    "    return grid_canvas\n",
    "end\n",
    "\n",
    "function loss_function(model, ps, st, X)\n",
    "    (y, μ, logσ²), st = model(X, ps, st)\n",
    "    reconstruction_loss = MSELoss(; agg=sum)(y, X)\n",
    "    kldiv_loss = -sum(1 .+ logσ² .- μ .^ 2 .- exp.(logσ²)) / 2\n",
    "    loss = reconstruction_loss + kldiv_loss\n",
    "    return loss, st, (; y, μ, logσ², reconstruction_loss, kldiv_loss)\n",
    "end\n",
    "\n",
    "function generate_images(\n",
    "    model, ps, st; num_samples::Int=128, num_latent_dims::Int, decode_compiled=nothing\n",
    ")\n",
    "    z = get_device((ps, st))(randn(Float32, num_latent_dims, num_samples))\n",
    "    if decode_compiled === nothing\n",
    "        images, _ = decode(model, z, ps, Lux.testmode(st))\n",
    "    else\n",
    "        images, _ = decode_compiled(model, z, ps, Lux.testmode(st))\n",
    "        images = cpu_device()(images)\n",
    "    end\n",
    "    return create_image_grid(images, 8, num_samples ÷ 8)\n",
    "end\n",
    "\n",
    "function reconstruct_images(model, ps, st, X)\n",
    "    (recon, _, _), _ = model(X, ps, Lux.testmode(st))\n",
    "    recon = cpu_device()(recon)\n",
    "    return create_image_grid(recon, 8, size(X, ndims(X)) ÷ 8)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function main(;\n",
    "    batchsize=128,\n",
    "    image_size=(64, 64),\n",
    "    num_latent_dims=8,\n",
    "    max_num_filters=64,\n",
    "    seed=0,\n",
    "    epochs=50,\n",
    "    weight_decay=1.0e-5,\n",
    "    learning_rate=1.0e-3,\n",
    "    num_samples=batchsize,\n",
    ")\n",
    "    rng = Xoshiro()\n",
    "    Random.seed!(rng, seed)\n",
    "\n",
    "    cvae = CVAE(rng; num_latent_dims, image_shape=(image_size..., 1), max_num_filters)\n",
    "    ps, st = xdev(Lux.setup(rng, cvae))\n",
    "\n",
    "    z = xdev(randn(Float32, num_latent_dims, num_samples))\n",
    "    decode_compiled = Reactant.with_config(;\n",
    "        dot_general_precision=PrecisionConfig.HIGH,\n",
    "        convolution_precision=PrecisionConfig.HIGH,\n",
    "    ) do\n",
    "        @compile decode(cvae, z, ps, Lux.testmode(st))\n",
    "    end\n",
    "    x = xdev(randn(Float32, image_size..., 1, batchsize))\n",
    "    cvae_compiled = Reactant.with_config(;\n",
    "        dot_general_precision=PrecisionConfig.HIGH,\n",
    "        convolution_precision=PrecisionConfig.HIGH,\n",
    "    ) do\n",
    "        @compile cvae(x, ps, Lux.testmode(st))\n",
    "    end\n",
    "\n",
    "    train_dataloader = xdev(loadmnist(batchsize, image_size))\n",
    "\n",
    "    opt = AdamW(; eta=learning_rate, lambda=weight_decay)\n",
    "\n",
    "    train_state = Training.TrainState(cvae, ps, st, opt)\n",
    "\n",
    "    @printf \"Total Trainable Parameters: %0.4f M\\n\" (Lux.parameterlength(ps) / 1.0e6)\n",
    "\n",
    "    empty_row, model_img_full = nothing, nothing\n",
    "\n",
    "    for epoch in 1:epochs\n",
    "        loss_total = 0.0f0\n",
    "        total_samples = 0\n",
    "\n",
    "        start_time = time()\n",
    "        for (i, X) in enumerate(train_dataloader)\n",
    "            (_, loss, _, train_state) = Training.single_train_step!(\n",
    "                AutoEnzyme(), loss_function, X, train_state; return_gradients=Val(false)\n",
    "            )\n",
    "\n",
    "            loss_total += loss\n",
    "            total_samples += size(X, ndims(X))\n",
    "\n",
    "            if i % 250 == 0 || i == length(train_dataloader)\n",
    "                throughput = total_samples / (time() - start_time)\n",
    "                @printf \"Epoch %d, Iter %d, Loss: %.7f, Throughput: %.6f im/s\\n\" epoch i loss throughput\n",
    "            end\n",
    "        end\n",
    "        total_time = time() - start_time\n",
    "\n",
    "        train_loss = loss_total / length(train_dataloader)\n",
    "        throughput = total_samples / total_time\n",
    "        @printf \"Epoch %d, Train Loss: %.7f, Time: %.4fs, Throughput: %.6f im/s\\n\" epoch train_loss total_time throughput\n",
    "\n",
    "        if IN_VSCODE || epoch == epochs\n",
    "            recon_images = reconstruct_images(\n",
    "                cvae_compiled,\n",
    "                train_state.parameters,\n",
    "                train_state.states,\n",
    "                first(train_dataloader),\n",
    "            )\n",
    "            gen_images = generate_images(\n",
    "                cvae,\n",
    "                train_state.parameters,\n",
    "                train_state.states;\n",
    "                num_samples,\n",
    "                num_latent_dims,\n",
    "                decode_compiled,\n",
    "            )\n",
    "            if empty_row === nothing\n",
    "                empty_row = similar(gen_images, image_size[1], size(gen_images, 2))\n",
    "                fill!(empty_row, 0)\n",
    "            end\n",
    "            model_img_full = vcat(recon_images, empty_row, gen_images)\n",
    "            IN_VSCODE && display(model_img_full)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return model_img_full\n",
    "end\n",
    "\n",
    "img = main()\n",
    "nothing #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "img #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.7",
   "language": "julia"
  }
 },
 "nbformat": 4
}
